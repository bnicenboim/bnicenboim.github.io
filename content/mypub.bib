% This file was created with JabRef 2.10b2.---
% Encoding: ISO8859_1

@unpublished{Boelders2024a,
	author = {Boelders, Sander Martijn and Nicenboim, Bruno and Butterbrod, Elke and de Baene, Wouter and Postma, Eric and Rutten, Geert-Jan and Ong, Lee-Ling and Gehring, Karin},
	title = {Predicting cognitive function three months after surgery in patients with a glioma},
	 notes="under review",
	year = {2024},
	doi = {10.1101/2024.10.08.24315076},
	publisher = {Cold Spring Harbor Laboratory Press},
	eprint = {https://www.medrxiv.org/content/early/2024/10/08/2024.10.08.24315076.full.pdf},
	journal = {medRxiv}
}

@article{10.1093/neuonc/noae144.196,
    author = {Boelders, S M and Nicenboim, B and Postma, E O and Ong, L S and Gehring, K},
    title = {Modeling uncertainty in individual predictions of cognitive functioning for untreated glioma patients using {Bayesian} regression and clinical variables},
    journal = {Neuro-Oncology},
    volume = {26},
    number = {Supplement_5},
    pages = {v60-v60},
    year = {2024},
    month = {10},
    abstract = {Cognitive functioning is increasingly considered when making treatment decisions for patients with a glioma in view of a personalized onco-functional balance (balancing survival against the preservation of function). Previous research using machine-learning models found that predicting pre-operative cognitive functioning based on clinical variables resulted in accurate predictions for some, but inaccurate predictions for other patients. Therefore, the current study sets out to use Bayesian models to improve predictions while also providing estimates of uncertainty for each individual prediction. Pre-operative cognitive functioning was predicted for 340 patients with a glioma across eight cognitive tests. This was done using six increasingly complex Bayesian regression models including hierarchical models conditioned on tumor grade. Models used a comprehensive set of predictors associated with cognitive functioning in the literature. Point-wise predictions were compared against one another and previous work using machine learning. The best-performing model (R2) was interpreted and examples of how Bayesian prediction models can be applied in clinical practice were provided. Bayesian models outperformed the machine-learning models used in previous work. Predictions, however, remained uncertain. The best-performing model allowed coefficients and intercepts to differ across tumors with a different grade while pulling the estimates toward the population mean. Moreover, the best-performing model included regularizing priors, causing it to use most variables for prediction while not relying strongly on any variable. Bayesian models resulted in better predictions than machine learning models while also providing estimates of uncertainty for individual predictions. For the best possible predictions, tumors with a different grade are best modeled as different, yet related. Moreover, a holistic view of patients’ cognitive functioning is necessary. The uncertainty in individual predictions exemplifies the importance of measures of uncertainty for clinical practice.},
    issn = {1522-8517},
    doi = {10.1093/neuonc/noae144.196},
    url = {https://doi.org/10.1093/neuonc/noae144.196},
    eprint = {https://academic.oup.com/neuro-oncology/article-pdf/26/Supplement\_5/v60/59832826/noae144.196.pdf}
}





@article{dubova_et_al_2025,
author = {Marina Dubova  and Suyog Chandramouli  and Gerd Gigerenzer  and Peter Grünwald  and William Holmes  and Tania Lombrozo  and Marco Marelli  and Sebastian Musslick  and Bruno Nicenboim  and Lauren N. Ross  and Richard Shiffrin  and Martha White  and Eric-Jan Wagenmakers  and Paul-Christian Bürkner  and Sabina J. Sloman },
title = {Is {Ockham's} razor losing its edge? {New} perspectives on the principle of model parsimony},
journal = {Proceedings of the National Academy of Sciences},
volume = {122},
number = {5},
pages = {e2401230121},
year = {2025},
doi = {10.1073/pnas.2401230121},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.2401230121},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.2401230121},
abstract = {The preference for simple explanations, known as the parsimony principle, has long guided the development of scientific theories, hypotheses, and models. Yet recent years have seen a number of successes in employing highly complex models for scientific inquiry (e.g., for 3D protein folding or climate forecasting). In this paper, we reexamine the parsimony principle in light of these scientific and technological advancements. We review recent developments, including the surprising benefits of modeling with more parameters than data, the increasing appreciation of the context-sensitivity of data and misspecification of scientific models, and the development of new modeling tools. By integrating these insights, we reassess the utility of parsimony as a proxy for desirable model traits, such as predictive accuracy, interpretability, effectiveness in guiding new research, and resource efficiency. We conclude that more complex models are sometimes essential for scientific progress, and discuss the ways in which parsimony and complexity can play complementary roles in scientific modeling practice.}
}


@article{vanDoorn2023,
author={van Doorn, Johnny and Haaf, Julia M. and Stefan, Angelika M. and Wagenmakers, Eric-Jan and Cox, Gregory Edward and Davis-Stober, Clintin P. and Heathcote, Andrew and Heck, Daniel W. and Kalish, Michael and Kellen, David and Matzke, Dora and Morey, Richard D. and Nicenboim, Bruno and van Ravenzwaaij, Don and Rouder, Jeffrey N. and Schad, Daniel J. and Shiffrin, Richard M. and Singmann, Henrik and Vasishth, Shravan and Ver{\'i}ssimo, Jo{\~a}o and Bockting, Florence and Chandramouli, Suyog and Dunn, John C. and Gronau, Quentin F. and Linde, Maximilian and McMullin, Sara D. and Navarro, Danielle and Schnuerch, Martin and Yadav, Himanshu and Aust, Frederik}, title={Bayes Factors for Mixed Models: a Discussion},
journal={Computational Brain {\&} Behavior}, 
year={2023},
month={Mar},
day={01},
volume={6},
number={1},
pages={140-158},
issn={2522-087X},
doi={10.1007/s42113-022-00160-3},
eprint={https://link.springer.com/content/pdf/10.1007/s42113-022-00160-3.pdf?pdf=button}
}



@article{Vasishth2023,
  author={Vasishth, Shravan and Yadav, Himanshu and Schad, Daniel J. and Nicenboim, Bruno},
  title={Sample Size Determination for {Bayesian} Hierarchical Models Commonly Used in Psycholinguistics},
  journal={Computational Brain {\&} Behavior},
  year={2023},
  month={Mar},
  day={01},
  volume={6},
  number={1},
  pages={102-126},
  issn={2522-087X},
  doi={10.1007/s42113-021-00125-y},
  eprint={https://link.springer.com/content/pdf/10.1007/s42113-021-00125-y.pdf?pdf=button}
}



@book{Nicenboimetal,
      title     = "An Introduction to {Bayesian} Data Analysis for Cognitive Science",
      author    = "Bruno Nicenboim and Daniel Schad and Shravan Vasishth",
      year      = "in preparation",
  eprint   = {https://vasishth.github.io/Bayes_CogSci/}
    }
    

@article{Stone2022,
    author = {Stone, Kate and Nicenboim, Bruno and Vasishth, Shravan and Rösler, Frank},
    title = "{Understanding the effects of constraint and predictability in ERP}",
    journal = {Neurobiology of Language},
    pages = {1-71},
    year = {2022},
    month = {12},
    issn = {2641-4368},
    doi = {10.1162/nol_a_00094},
    customb = {https://osf.io/fndk5/},
    eprint = {https://direct.mit.edu/nol/article-pdf/doi/10.1162/nol\_a\_00094/2062866/nol\_a\_00094.pdf}
}



@article{PAttersonEtAl,
  issn = {1664-1078},
DOI={10.3389/fpsyg.2021.672927},      
eprint = {http://www.frontiersin.org/language_sciences/10.3389/fpsyg.2016.00280/abstract},
  number = {},
  year = {2022},
VOLUME={12},      
journal = {Frontiers in Psychology, Language Sciences},
  title = {A {Bayesian} approach to {German} personal and demonstrative pronouns},
  eprint   = {https://www.frontiersin.org/articles/10.3389/fpsyg.2021.672927/abstract},
  customb = {},
  author = {Clare Patterson and Petra B. Schumacher and Bruno Nicenboim and Johannes Hagen and Andrew Kehler}
}

@article{schad2022workflow,
      title={Workflow Techniques for the Robust Use of {Bayes} Factors}, 
      author={Daniel J. Schad and Bruno Nicenboim and Paul-Christian Bürkner and Michael Betancourt and Shravan Vasishth},
	DOI = {10.1037/met0000472},
	Year = {2022},
	Journal = {Psychological methods},
	ISSN = {1082-989X},
	customb = {https://osf.io/y354c/},
      journal ={Psychological Methods},
      eprint={https://arxiv.org/abs/2103.08744}
}

@article{PAttAl2017,
  journal = {Glossa: {A} journal of general linguistics. },
  title = {Does antecedent complexity affect ellipsis processing? An empirical investigation},
  year ={2017},
  Volume=2,
  number=1,
  pages={71},
  doi = {10.5334/gjgl.290},
eprint ={https://www.glossa-journal.org/articles/abstract/10.5334/gjgl.290/},
  author = {Dario Paape and Bruno Nicenboim  and Shravan Vasishth}
}

@article{NicenboimEtAl2016When,
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2016.00280 },
 eprint = {http://www.frontiersin.org/language_sciences/10.3389/fpsyg.2016.00280/abstract},
  number = {280},
  year = {2016},
  volume = {7},
  journal = {Frontiers in Psychology },
  title = {When high-capacity readers slow down and low-capacity readers speed up: {Working} memory and locality effects},
  eprint   = {https://www.frontiersin.org/articles/10.3389/fpsyg.2016.00280/full},
  customb = {https://github.com/bnicenboim/papers/tree/master/NicenboimEtAl2016.%20When%20High-Capacity%20Readers%20Slow%20Down%20and%20Low-Capacity%20Readers%20Speed%20Up:%20Working%20Memory%20and%20Locality%20Effects},
  author = {Bruno Nicenboim and Pavel Logačev and Carolina Gattei and Shravan Vasishth}
}
@Article{NicenboimEtAl2015Working,
  Title                    = {Working memory differences in long-distance dependency resolution},
  Author                   = {Bruno Nicenboim and Shravan Vasishth and Carolina Gattei and Mariano Sigman and Reinhold Kliegl},
  Year                     = {2015},
  Doi                      = {10.3389/fpsyg.2015.00312},
  ISSN                     = {1664-1078},
  Number                   = {312},
  eprint = {http://www.frontiersin.org/language_sciences/10.3389/fpsyg.2015.00312/abstract},
  Volume                   = {6},
    customb = {https://github.com/bnicenboim/papers/tree/master/NicenboimEtAl2015.%20Working%20memory%20differences%20in%20long-distance%20dependency%20resolution},  
  Journal                  = {Frontiers in Psychology}
}



@ARTICLE{NicenboimVasishth2016llcII,
   author = {Bruno Nicenboim and Shravan Vasishth},
    title = "{Statistical methods for linguistic research: {Foundational} Ideas - {Part} {II}}",
  journal = {Language and Linguistics Compass},
   eprint = {https://arxiv.org/abs/1602.00245},
  pages = {591--613},
  doi = {10.1111/lnc3.12207},
  issn = {1749-818X},
  number = {11},
  volume = {10},
     year = "2016"
}


@article{VasishthNicenboim2016llcI,
author = {Vasishth, Shravan and Nicenboim, Bruno},
title = {Statistical Methods for Linguistic Research: {Foundational} Ideas - {Part I}},
journal = {Language and Linguistics Compass},
volume = {10},
number = {8},
issn = {1749-818X},
eprint = {https://arxiv.org/abs/1601.01126},
doi = {10.1111/lnc3.12201},
pages = {349--369},
year = {2016}
}

@article{NicenboimEtAl2018Number,
  Title                    = {Exploratory and confirmatory analyses in sentence processing: {A} case study of number interference in {German}},
  Author                   = { Bruno Nicenboim and Shravan Vasishth and Felix Engelmann and Katja Suckow},
  journal ={Cognitive Science},
    doi={10.1111/cogs.12589},
    volume = {42},
number = {S4},
  pages = {1075--1100} ,
  year = {2018},
  eprint ={https://osf.io/preprints/psyarxiv/u2kqg/},
  customb = {https://osf.io/4dg9b/}
}


@article{NicenboimEtAl2017EDAPS,
  Title                    = {Using meta-analysis for evidence synthesis: {The} case of
incomplete neutralization in {German}},
  Author                   = { Bruno Nicenboim and  Timo B. Roettger and Shravan Vasishth },
  doi = {10.1016/j.wocn.2018.06.001},
  year = 2018,
eprint = {https://psyarxiv.com/p5a4z/},
      customb = {https://osf.io/g5ndw/},
      volume="70",
       pages= "39--55",
  journal= {Journal of Phonetics}
}

@article{VasishthEtAl2017EDAPS,
  Title                    = {Bayesian data analysis in the phonetic sciences: {A} tutorial introduction},
  Author                   = {Shravan Vasishth and Bruno Nicenboim and Mary E. Beckman and Fangfang Li and Eunjong Kong},
doi = {10.1016/j.wocn.2018.07.008},
eprint = {https://osf.io/5pj49/},
  customb = {https://osf.io/g4zpv/},
  volume="71",
  pages= "147--161",
  year = {2018},
  journal= {Journal of Phonetics}
}


@unpublished{Vasishth_Nicenboim_Chopin_Ryder_2017,
  title={Bayesian hierarchical finite mixture models of reading times: {A} case study},year = 2017,
  DOI={10.17605/OSF.IO/FWX3S},
  notes={unpublished},
  author={Vasishth, Shravan and Nicenboim, Bruno and Chopin, Nicolas and Ryder, Robin},
eprint = {https://osf.io/v5nps/}
}


@article{nicenboim_vasishth_rosler_2019,
 title={Are words pre-activated probabilistically during sentence comprehension? {Evidence} from new data and a {Bayesian} random-effects meta-analysis using publicly available data},
eprint ={https://psyarxiv.com/2atrh/},
 DOI={10.1016/j.neuropsychologia.2020.107427},
volume = {142},
pages = {107427},
year = {2020},
issn = {0028-3932},
 author={Nicenboim, Bruno and Vasishth, Shravan and Rösler, Frank},
journal = "Neuropsychologia"
}

@article{lisson_etal_2020,
 title={A computational evaluation of two models of retrieval processes in sentence processing in aphasia},
 eprint={https://psyarxiv.com/r7dn5},
 DOI={10.1111/cogs.12956},
 author={Lisson, Paula and Pregla, Dorothea and Nicenboim, Bruno and Paape, Dario and van het Nederend, Mick L and Burchert, Frank and Stadie, Nicole and Caplan, David and Vasishth, Shravan},
 journal = {Cognitive Science},
 month = {apr},	
 publisher = {Wiley},	
 volume = {45},	
 number = {4},	
 year={2021}
}


@article{albert_nicenboim_2020,
 title={Modeling Sonority in Terms of Pitch Intelligibility With the Nucleus Attraction Principle},
 eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.13161},
 DOI={doi.or1/cogs.13161},
 journal = {Cognitive Science},
volume = {46},
number = {7},
pages = {e13161},
keywords = {Sonority, Pitch intelligibility, Periodic energy, Bayesian data analysis, Speech perception, Phonetics and phonology},
 author={Albert, Aviad and Nicenboim, Bruno},
 month={Oct},
 year = {2022},
  customb ={https://osf.io/y477r}

}


@article{NicenboimVasishth2017Models,
  Title                    = {Models of Retrieval in Sentence Comprehension: {A} computational evaluation using {Bayesian} hierarchical modeling},
  Author                   = { Bruno Nicenboim and Shravan Vasishth },
volume = "99",
pages = "1 --34",
year = "2018",
issn = "0749-596X",
doi = "10.1016/j.jml.2017.08.004",
  eprint = {https://arxiv.org/abs/1612.04174},
    journal ={Journal of Memory and Language},
  customb ={https://osf.io/a5ymk}
}

@article{vasishth_nicenboim_engelmann_burchert_2019,
 title={Computational models of retrieval processes in sentence processing},
 eprint ={https://psyarxiv.com/e4jds/},
 DOI={10.1016/j.tics.2019.09.003},
volume = "23",
number = "11",
pages = "968 - 982",
year = "2019",
issn = "1364-6613",
 journal = {Trends in Cognitive Sciences},
 author={Vasishth, Shravan and Nicenboim, Bruno and Engelmann, Felix  and Burchert, Frank},
 year={2019}
}

@Inproceedings{Nicenboim2018StanCon,
  Title                    = {The implementation of a model of choice: {The} (truncated) linear ballistic accumulator},
  Author                   = {Nicenboim, Bruno},
  Booktitle                = {{StanCon}},
  Year                     = {2018},
doi = {10.5281/zenodo.1465990},
  Location                 = {Aalto University, Helsinki, Finland},
  Month                    = {8},
eprint = {https://htmlpreview.github.io/?https://github.com/stan-dev/stancon_talks/blob/master/2018-helsinki/Contributed-Talks/nicenboim/LBA_stancon2018.html},
  customd = {https://www.youtube.com/watch?v=wcpjZC9AV84&t=1h44m33s}
}


@Inproceedings{Nicenboim2023ICCM,
  Title                    = {The {CoFI} Reader: {A} Continuous Flow of Information approach to modeling reading},
  Author                   = {Nicenboim, Bruno},
  Booktitle                = {{MathPsych/ICCM/EMPG}},
  Year                     = {2023},
  Location                 = {University of Amsterdam, the Netherlands},
  Month                    = {7},
eprint = {https://mathpsych.org/presentation/998#/document}
}

@Inproceedings{VasishthEtAl2017Modelling,
  Title                    = {Modelling dependency completion in sentence comprehension as a {Bayesian} hierarchical mixture process: {A} case study involving {Chinese} relative clauses},
  Author                   = {Shravan Vasishth and Nicolas Chopin and Robin Ryder and Bruno Nicenboim},
  eprint = {https://arxiv.org/abs/1702.00564v2},
       year = 2017,
    Booktitle={Proceedings of Cognitive Science Conference},
Location={London, UK}
}


@Inproceedings{VasishthEtAl2017Feature,
   author = {{Vasishth}, S. and {Jaeger}, L.~A. and {Nicenboim}, B.},
    title = "{Feature overwriting as a finite mixture process: {Evidence} from comprehension data}",
archivePrefix = "arXiv",
   eprint = {https://arxiv.org/abs/1703.04081},
     Booktitle={Proceedings of MathPsych/ICCM Conference},
Location={Warwick, UK},
      year = 2017
}






@Inproceedings{NicenboimVasishth2017StanCon,
  Title                    = {Models of Retrieval in Sentence Comprehension},
  Author                   = {Nicenboim, Bruno and Vasishth, Shravan},
  Booktitle                = {{StanCon}},
  Year                     = {2017},
  Location                 = {Columbia University New York, NY},
  Month                    = {1},
  note = {(superseeded by 10.1016/j.jml.2017.08.004)},
  customa ={http://mc-stan.org/events/stancon2017-notebooks/stancon2017-nicenboim-vasishth-retrieval-models.html},
  customd = {https://youtu.be/DJ0c7Bm5Djk?t=6h18m1s}
}


@Article{SchadEtAl2024Dataaggregationcan,
  author           = {Schad, Daniel J. and Nicenboim, Bruno and Vasishth, Shravan},
  Year             = {2024},
  journaltitle     = {Psychological Methods},
  title            = {Data aggregation can lead to biased inferences in {Bayesian} linear mixed models and {Bayesian} analysis of variance.},
  doi              = {10.1037/met0000621},
  issn             = {1082-989X},
  customa = {https://arxiv.org/abs/2203.02361},
  publisher        = {American Psychological Association (APA)}
}




@article{benartzi2022,
 title={Computational mechanisms underlying latent inverse value updating of unchosen actions},
 volume = {9},
 journal = {Science Advances},
number = {42},
pages = {eadi2704},
year = {2023},
doi = {10.1126/sciadv.adi2704},
eprint = {https://www.science.org/doi/pdf/10.1126/sciadv.adi2704},
 author={Ben-Artzi, Ido and Kessler, Yoav and Nicenboim, Bruno and Shahar, Nitzan},
 year={2023}
}

