[
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software",
    "section": "",
    "text": "An R package for tidy-ish manipulation of EEG data. It is fully functional, but it’s only able to do basic preprocessing.\n\n\n\nAn R package for estimating the log-probabilities of words in a given context using transformer models. The package provides an interface for utilizing pre-trained transformer models (such as GPT-2 or BERT) to obtain word probabilities. These log-probabilities are often utilized as predictors in psycholinguistic studies."
  },
  {
    "objectID": "software.html#eeguana",
    "href": "software.html#eeguana",
    "title": "Software",
    "section": "",
    "text": "An R package for tidy-ish manipulation of EEG data. It is fully functional, but it’s only able to do basic preprocessing."
  },
  {
    "objectID": "software.html#pangoling",
    "href": "software.html#pangoling",
    "title": "Software",
    "section": "",
    "text": "An R package for estimating the log-probabilities of words in a given context using transformer models. The package provides an interface for utilizing pre-trained transformer models (such as GPT-2 or BERT) to obtain word probabilities. These log-probabilities are often utilized as predictors in psycholinguistic studies."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bruno Nicenboim",
    "section": "",
    "text": "Email:\n[initial].[lastname] [at] tilburguniversity.edu\n\n\nOffice:\nD108, Dante Building, Tilburg University\n\n\nAddress:\nDepartment of Computational Cognitive Science,\n\n\n\nCognitive Science and Artificial Intelligence\n\n\n\nTilburg University\n\n\n\nPO Box 90153\n\n\n\n5000 LE Tilburg\n\n\n\nThe Netherlands"
  },
  {
    "objectID": "index.html#computational-cognitive-modeling",
    "href": "index.html#computational-cognitive-modeling",
    "title": "Bruno Nicenboim",
    "section": "Computational Cognitive Modeling",
    "text": "Computational Cognitive Modeling\nI study computational cognitive modeling of psycholinguistic phenomena, with some examples below:\n\nNicenboim, B. (2023). “The CoFI Reader: A Continuous Flow of Information approach to modeling reading.” In: MathPsych/ICCM/EMPG. University of Amsterdam, the Netherlands. [read]\nNicenboim, B. and S. Vasishth (2018). “Models of Retrieval in Sentence Comprehension: A computational evaluation using Bayesian hierarchical modeling.” In: Journal of Memory and Language, 99, pp. 1–34. ISSN: 0749-596X. DOI: 10.1016/j.jml.2017.08.004. [read]\n\nI am also interested in broader aspects of computational modeling:\n\nDubova, M., S. Chandramouli, G. Gigerenzer, P. Grünwald, W. Holmes, T. Lombrozo, M. Marelli, S. Musslick, B. Nicenboim, L. N. Ross, et al. (2025). “Is Ockham’s razor losing its edge? New perspectives on the principle of model parsimony.” In: Proceedings of the National Academy of Sciences, 122(5), p. e2401230121. DOI: 10.1073/pnas.2401230121. [read]\nI was one of the organizers of the first Computational Psycholinguistics Meeting (2025): a new recurring meeting dedicated exclusively to computational psycholinguistics.\nI organized the Lorentz Centre “Cognitive Modeling of Complex Behavior” workshop in January 2024, along with Riccardo Fusaroli and Marieke van Vugt. This hands-on event focused on collaborative modeling of cognitive phenomena. See here."
  },
  {
    "objectID": "index.html#eeg-in-psycholinguistics",
    "href": "index.html#eeg-in-psycholinguistics",
    "title": "Bruno Nicenboim",
    "section": "EEG in Psycholinguistics",
    "text": "EEG in Psycholinguistics\nI also work with EEG in psycholinguistics:\n\nK. Stone, B. Nicenboim, S. Vasishth, et al. “Understanding the effects of constraint and predictability in ERP.” In: Neurobiology of Language (Dec. 2022), pp. 1-71. DOI: 10.1162/nol_a_00094. [read]\nB. Nicenboim, S. Vasishth, and F. Rösler. “Are words pre-activated probabilistically during sentence comprehension? Evidence from new data and a Bayesian random-effects meta-analysis using publicly available data.” In: Neuropsychologia, 142 (2020), p. 107427. DOI: 10.1016/j.neuropsychologia.2020.107427. [read]\n\nI also developed an R package for EEG data manipulation: eeguana."
  },
  {
    "objectID": "index.html#bayesian-statistics",
    "href": "index.html#bayesian-statistics",
    "title": "Bruno Nicenboim",
    "section": "Bayesian Statistics",
    "text": "Bayesian Statistics\nBayesian statistics provides a powerful framework for cognitive science by allowing principled uncertainty quantification and hierarchical modeling. I mostly work with Stan (and brms):\n\nIntroduction to Bayesian Data Analysis for Cognitive Science , co-authored with Shravan Vasishth and Daniel Schad. You can [buy it] or [read it for free]."
  },
  {
    "objectID": "index.html#data-and-code",
    "href": "index.html#data-and-code",
    "title": "Bruno Nicenboim",
    "section": "Data and Code",
    "text": "Data and Code\nMost of the data and code from my published papers are available on the OSF website, with some exceptions in my GitHub repository."
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "License",
    "section": "",
    "text": "MIT License\nCopyright (c) 2026 Bruno Nicenboim\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "posts/posts/2026-01-06-a-simple-way-to-model-rankings-with-stan/index.html",
    "href": "posts/posts/2026-01-06-a-simple-way-to-model-rankings-with-stan/index.html",
    "title": "A simple way to model rankings with Stan",
    "section": "",
    "text": "Update Notice\n\n\n\nThis is an updated version of a post originally published on March 21, 2021.\nI’ve updated this post in January 2026 to work with current versions of Stan and R packages. The main changes include:\n\nUpdated Stan syntax to current standards\nUsing cmdstanr instead of rstan and some other R packages.\n\nThe core content and ideas remain the same."
  },
  {
    "objectID": "posts/posts/2026-01-06-a-simple-way-to-model-rankings-with-stan/index.html#the-initial-problem",
    "href": "posts/posts/2026-01-06-a-simple-way-to-model-rankings-with-stan/index.html#the-initial-problem",
    "title": "A simple way to model rankings with Stan",
    "section": "The initial problem",
    "text": "The initial problem\nI wrote what I thought was the generative process for some modeling work, and it looked too common to not have a name, so I started asking around on what it was a very popular website back in 2021, Twitter.\nOne useful clue was about the exploded logit distribution.1\n\nIn this post, I’ll show how this model can be fit in the probabilistic programming language Stan, and how it can be used to describe the underlying order of ranking data.\nI’m going to load some R packages that will be useful throughout this post.\n\nlibrary(tidytable) # Nicer alternative to dplyr and purrr\nlibrary(ggplot2) # Nice plots\nlibrary(extraDistr) # More distributions\nlibrary(rcorpora) # Get random words\nlibrary(cmdstanr) # Lightweight Stan interface\nlibrary(bayesplot) # Nice Bayesian plots\nset.seed(42)  # Keep everything R the same (not for Stan though)"
  },
  {
    "objectID": "posts/posts/2026-01-06-a-simple-way-to-model-rankings-with-stan/index.html#ranking-data",
    "href": "posts/posts/2026-01-06-a-simple-way-to-model-rankings-with-stan/index.html#ranking-data",
    "title": "A simple way to model rankings with Stan",
    "section": "Ranking data",
    "text": "Ranking data\nRanking data appear when we care about the underlying order that certain elements have. We might want to know which are the best horses after looking at several races (Gakis et al. 2018), which is the best candidate for a job after a series of interviewers talked to several candidates. More in line with cognitive science, we might want to know which are the best possible completions for a sentence or the best exemplars of a category.\nOne way to get a ranking of exemplars of a category, for example, is to present them to participants and ask them to order all (or a subset) of them (see Barsalou 1985).\n\nA ranking simulation using pizza toppings\n\n\ntoppings &lt;- corpora(\"foods/pizzaToppings\")$pizzaToppings\nN_toppings &lt;- length(toppings)\ntoppings\n\n [1] \"anchovies\"        \"artichoke\"       \n [3] \"bacon\"            \"breakfast bacon\" \n [5] \"Canadian bacon\"   \"cheese\"          \n [7] \"chicken\"          \"chili peppers\"   \n [9] \"feta\"             \"garlic\"          \n[11] \"green peppers\"    \"grilled onions\"  \n[13] \"ground beef\"      \"ham\"             \n[15] \"hot sauce\"        \"meatballs\"       \n[17] \"mushrooms\"        \"olives\"          \n[19] \"onions\"           \"pepperoni\"       \n[21] \"pineapple\"        \"sausage\"         \n[23] \"spinach\"          \"sun-dried tomato\"\n[25] \"tomatoes\"        \n\n\nLet’s say that we want to know the underlying order of pizza toppings. For the modeling, I’m going to assume that the toppings are ordered according to an underlying value, which also represents how likely it is for each topping to be the exemplar of their category.\nTo get a known ground truth for the ranking, I’m going to simulate an order of pizza toppings. I assign probabilities that sum up to one to the toppings by drawing a random sample from a Dirichlet distribution. The Dirichlet distribution is the generalization of the Beta distribution. It has a concentration parameter, usually \\(\\boldsymbol{\\alpha}\\), which is a vector as long as the probabilities we are sampling (25 here). When the vector is full of ones, the distribution is uniform: All probabilities are equally likely, so on average each one is \\(\\frac{1}{\\text{vector length}}\\) (\\(\\frac{1}{25}\\) here). By setting all the concentration parameters below one (namely \\(0.2\\)), I’m enforcing sparsity in the random values that I’m generating, that is, many probability values close to zero.\nThese is the true order that I’m assuming here:\n\n# all elements of the vector are 0.2\nalpha &lt;- rep(.2, N_toppings)\n# Generate one draw from a Dirichlet distribution\nP_toppings &lt;- c(rdirichlet(1, alpha)) %&gt;%\n  # Add names\n  setNames(toppings) %&gt;%\n  # Sort from the best exemplar\n  sort(decreasing = TRUE)\nP_toppings %&gt;%\n  round(3)\n\n breakfast bacon          chicken             feta \n           0.294            0.241            0.087 \n       anchovies sun-dried tomato           olives \n           0.087            0.077            0.057 \n       pepperoni        artichoke           cheese \n           0.056            0.049            0.010 \n  Canadian bacon            bacon              ham \n           0.008            0.008            0.006 \n       meatballs    chili peppers           garlic \n           0.004            0.004            0.004 \n     ground beef         tomatoes        hot sauce \n           0.003            0.003            0.002 \n          onions          sausage        pineapple \n           0.000            0.000            0.000 \n         spinach        mushrooms   grilled onions \n           0.000            0.000            0.000 \n   green peppers \n           0.000 \n\n\n\nGiven these values, if I were to ask a participant “What’s the most appropriate topping for a pizza?” I would assume that 29.37 percent of the time, I would get breakfast bacon.\n\nEssentially, we expect something like this to be happening:\n\\[\n\\text{response} \\sim \\text{Categorical}(\\Theta_{\\text{toppings}})\n\\]\nWith \\(\\Theta_{\\text{toppings}}\\) representing the different probabilities for each topping. The probability mass function of the categorical distribution is absurdly simple: It’s just the probability of the outcome.\n\\[\np(x = i) = \\Theta_i\n\\]\nwhere \\(i = \\{\\)breakfast bacon, chicken, feta, anchovies, sun-dried tomato, olives, pepperoni, artichoke, cheese, Canadian bacon, bacon, ham, meatballs, chili peppers, garlic, ground beef, tomatoes, hot sauce, onions, sausage, pineapple, spinach, mushrooms, grilled onions, green peppers\\(\\}\\).\nWe can simulate this with 100 participants as follows:\n\nresponse &lt;- rcat(100, P_toppings, names(P_toppings))\n\nAnd this should match approximately P_toppings.\n\ntable(response)/100\n\nresponse\n breakfast bacon          chicken             feta \n            0.26             0.19             0.16 \n       anchovies sun-dried tomato           olives \n            0.07             0.15             0.06 \n       pepperoni        artichoke           cheese \n            0.01             0.08             0.00 \n  Canadian bacon            bacon              ham \n            0.02             0.00             0.00 \n       meatballs    chili peppers           garlic \n            0.00             0.00             0.00 \n     ground beef         tomatoes        hot sauce \n            0.00             0.00             0.00 \n          onions          sausage        pineapple \n            0.00             0.00             0.00 \n         spinach        mushrooms   grilled onions \n            0.00             0.00             0.00 \n   green peppers \n            0.00 \n\n\nIt seems that by only asking participants to give the best topping we could already deduce the underlying order…\nTrue, but one motivation for considering ranking data is the amount of information that we gather with a list due to their combinatorial nature. If we ask participants to rank \\(n\\) items, an answer consists in making a single selection out of \\(n!\\) possibilities. Ordering 7 pizza toppings, for example, constitutes making a single selection out of 5040 possibilities!\nIf we don’t relay on lists and there is sparcity, it requires a large number of participants until we get answers of low probability. (For example, we’ll need a very large number of participants until we hear something else but hammer as an exemplar of tools).\n\nNow, what happens if we ask about the second most appropriate topping for a pizza?\n\nNow we need to exclude the first topping that was given, and draw another sample from a categorical distribution. (We don’t allow the participant to repeat toppings, that is, to say that the best topping is pineapple and the second best is also pineapple). This means that now the probability of the topping already given is zero, and that we need to normalize our original probability values by dividing them by the new total probability (which will be lower than 1).\nHere, the probability of getting the element \\(j\\) (where \\(j \\neq i\\)) is\n\\[\np(x = j) = \\frac{\\Theta_j}{\\sum \\Theta_{[-i]}}\n\\]\nwhere \\(\\Theta_{[-i]}\\) represents the probabilities of all the outcomes except of \\(i\\), which was the first one.\n\nWe can go on with the third best topping, where we need to normalize the remaining probabilities by dividing by the new sum of probabilities (e.g., we remove elements \\(i\\) and \\(j\\)).\n\n\\[\np(x = k) = \\frac{\\Theta_k}{\\sum \\Theta_{[-i,-j]}}\n\\]\n\nWe can do this until we get to the last element, which will be drawn with probability 1.\n\nAnd this is the exploded logit distribution.\nThis process can be simulated in R as follows:\n\nrexploded &lt;-  function(n, ranked = 3, prob, labels = NULL){\n  # run n times\n  lapply(1:n, function(nn){\n    res &lt;- rep(NA, ranked)\n    if(!is.null(labels)){\n      res &lt;- factor(res, labels)\n    } else {\n      # if there are no labels, just 1,2,3,...\n      labels &lt;- seq_along(prob)\n    }\n    for(i in 1:ranked){\n      # normalize the probability so that it sums to 1\n      prob &lt;- prob/sum(prob)\n      res[i] &lt;- rcat(1, prob = prob, labels = labels)\n      # remove the choice from the set:\n      prob[res[i]] &lt;- 0\n    }\n    res\n  })\n}\n\nIf we would like to simulate 50 subjects creating a ranking of the best 7 toppings, we would do the following:\n\nres &lt;- rexploded(n = 50,\n                 ranked = 7,\n                 prob = P_toppings,\n                 labels = names(P_toppings))\n# subject 1:\nres[[1]]\n\n[1] sun-dried tomato artichoke        olives          \n[4] breakfast bacon  chicken          pepperoni       \n[7] anchovies       \n25 Levels: breakfast bacon chicken feta ... green peppers\n\n\n\n\n\n\n\n\n\n\n\nWe have simulated ranking data of pizza toppings, can we recover the original probability values and “discover” the underlying order?"
  },
  {
    "objectID": "posts/posts/2026-01-06-a-simple-way-to-model-rankings-with-stan/index.html#fitting-the-exploded-logistic-distribution-in-stan",
    "href": "posts/posts/2026-01-06-a-simple-way-to-model-rankings-with-stan/index.html#fitting-the-exploded-logistic-distribution-in-stan",
    "title": "A simple way to model rankings with Stan",
    "section": "Fitting the exploded logistic distribution in Stan",
    "text": "Fitting the exploded logistic distribution in Stan\nTo fit the model in Stan, I’m going to create a custom probability mass function that takes an array of integers, x, which represents a set of rankings, and a vector of probability values, theta, that sums up to one.\nThe logic of this function is that the probability mass function of a ranking \\(\\{i,j,k, \\ldots, N \\}\\) can be written as a product of normalized categorical distributions (where the first one is just divided by 1).\n\\[\np(x = \\{i,j,k,\\ldots\\}) = \\frac{\\Theta_i}{\\sum \\Theta} \\cdot \\frac{\\Theta_j}{\\sum \\Theta_{[-i]}} \\cdot \\frac{\\Theta_k}{\\sum \\Theta_{[-i, -j]}} \\ldots\n\\]\nFor Stan, we need the log-PDF. In log-space, products become sums, and divisions differences, and the log of \\(\\sum \\Theta\\) will be zero:\n\\[\n\\begin{aligned}\n\\log(p(x = \\{i,j,k,\\ldots\\})) =& \\log(\\Theta_i) - \\log(\\sum \\Theta) \\\\\n& + \\log(\\Theta_j) - \\log(\\sum \\Theta_{[-i]}) \\\\\n&+ \\log(\\Theta_k) - \\log(\\sum \\Theta_{[-i, -j]}) \\\\\n& + \\ldots\n\\end{aligned}\n\\]\nThe following Stan code has a custom function that follows this logic but iterating over the rankings. In each iteration, it aggregates in the variable out the addends of the log probability mass function, and turns the probability of selecting again the already ranked element to zero. I save this code as \"exploded.stan\".\n\nfunctions {\n  real exploded_lpmf(array[] int x, vector Theta){\n    real out = 0;\n    vector[num_elements(Theta)] thetar = Theta;\n    for(pos in x){\n      out += log(thetar[pos]) - log(sum(thetar));\n      thetar[pos] = 0;\n    }\n    return(out);\n  }\n}\ndata{\n  int N_ranking; // total times the choices were ranked\n  int N_ranked; // total choices ranked\n  int N_options; // total options\n  array[N_ranking, N_ranked] int res;\n}\nparameters {\n  simplex[N_options] Theta;\n}\nmodel {\n  target += dirichlet_lpdf(Theta | rep_vector(1, N_options));\n  for(r in 1:N_ranking){\n    target += exploded_lpmf(res[r] | Theta);\n  }\n}\n\nThe whole model includes the usual data declaration, the parameter Theta declared as a simplex (i.e., it sums to one), and a uniform Dirichlet prior for Theta. (I’m assuming that I don’t know how sparse the probabilities are).\nLet’s see if I can recover the parameter values.\n\n# Make the list of lists into a matrix\nres_matrix &lt;- t(sapply(res, as.numeric))\nldata &lt;- list(\n  res = res_matrix, \n  N_ranked = length(res[[1]]), \n  N_options = length(P_toppings), \n  N_ranking = length(res)\n) \n\nm_expl &lt;- cmdstan_model(\"exploded.stan\")\n\nf_exploded &lt;- m_expl$sample(\n  data = ldata,\n  seed = 123,\n  parallel_chains = 4,\n  refresh = 0\n)\n\n\nf_exploded\n\n variable    mean  median   sd  mad      q5     q95 rhat\n lp__     -724.97 -724.61 3.65 3.57 -731.42 -719.65 1.00\n Theta[1]    0.29    0.29 0.04 0.04    0.23    0.35 1.00\n Theta[2]    0.27    0.27 0.04 0.03    0.21    0.33 1.00\n Theta[3]    0.08    0.08 0.01 0.01    0.06    0.10 1.00\n Theta[4]    0.09    0.08 0.01 0.01    0.06    0.11 1.00\n Theta[5]    0.07    0.07 0.01 0.01    0.05    0.09 1.00\n Theta[6]    0.05    0.04 0.01 0.01    0.03    0.06 1.00\n Theta[7]    0.04    0.04 0.01 0.01    0.03    0.06 1.00\n Theta[8]    0.05    0.05 0.01 0.01    0.03    0.06 1.00\n Theta[9]    0.01    0.01 0.00 0.00    0.00    0.02 1.00\n ess_bulk ess_tail\n     1637     2191\n     5941     3310\n     4884     3247\n     5410     2878\n     5771     2956\n     5578     3435\n     5973     3091\n     6068     2815\n     5606     3141\n     6586     3244\n\n # showing 10 of 26 rows (change via 'max_rows' argument or 'cmdstanr_max_rows' option)\n\n\nI plot the posterior distributions of the probability values and the true probability values below.\n\nmcmc_recover_hist(f_exploded$draws(\"Theta\"),\n                  P_toppings,\n                  facet_args =\n                    list(scales = \"fixed\", ncol = 3)) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nIt looks reasonable. However, if we really want to be sure that this is working, we should probably use simulation based calibration (Talts et al. 2018)."
  },
  {
    "objectID": "posts/posts/2026-01-06-a-simple-way-to-model-rankings-with-stan/index.html#what-is-this-good-for",
    "href": "posts/posts/2026-01-06-a-simple-way-to-model-rankings-with-stan/index.html#what-is-this-good-for",
    "title": "A simple way to model rankings with Stan",
    "section": "What is this good for?",
    "text": "What is this good for?\nThis super simple example shows how to get an underlying ranking based on a set of responses from a number of subjects. It’s straightforward to adapt this model to data from participants ranking elements from different sets of the same size (e.g., 7 out of 25 toppings, 7 out of 25 tools). It’s a little less straightforward if the sets are of different sizes, e.g., rank 7 toppings out 25, but 7 tools out 50. This is just because Stan doesn’t allow ragged arrays. See this Stan Discourse thread for some tips on implementing the latter model."
  },
  {
    "objectID": "posts/posts/2026-01-06-a-simple-way-to-model-rankings-with-stan/index.html#could-this-be-used-as-a-cognitive-model-of-peoples-rankings",
    "href": "posts/posts/2026-01-06-a-simple-way-to-model-rankings-with-stan/index.html#could-this-be-used-as-a-cognitive-model-of-peoples-rankings",
    "title": "A simple way to model rankings with Stan",
    "section": "Could this be used as a cognitive model of people’s rankings?",
    "text": "Could this be used as a cognitive model of people’s rankings?\n\nMaybe. And I enter here in the realm of half baked research, ideal for a blog post.\nLee, Steyvers, and Miller (2014) show the implementation of a cognitive model for rank order data from the latent knowledge of participants, which is based on Thurstonian models (Thurstone 1927, 1931) fitted with Bayesian methods in JAGS (Johnson and Kuhn 2013).\nThe exploded logit model seems to be closely related to the Thurstonian model. The Thurstonian model assumes that each participant assigns an underlying score to each item of a set, which is drawn from a true score with normally distributed error. The score determines the order that the participant gives. We can think about the exploded logit similarly. While I modeled the underlying ranking based on probability values, one could assume that each participant \\(s\\) had their own score \\(\\mu_{is}\\) for each item (or pizza topping) \\(i\\), which is built as a common score \\(\\mu_i\\) together with some individual deviation \\(\\epsilon_{is}\\):\n\\[\n\\mu_{is} = \\mu_i + \\epsilon_{is}\n\\]\nIf we assume that \\(\\epsilon_{is}\\) has a Gumbel distribution, then the probability of \\(\\mu_{is}\\) being ranked first out of N options is determined by a softmax function:\n\\[\nP(i) = \\frac{\\exp(\\mu_i)}{\\sum \\exp(\\mu)}\n\\]\nwhere \\(\\mu\\) is the vector of scores for all elements of the set.\nAnd the probability of ordering \\(j\\) second is:\n\\[\nP(i,j,\\ldots) = \\frac{\\exp(\\mu_j)}{\\sum \\exp(\\mu_{[-i]})}\n\\]\nand so forth.\nThese last equations are essentially the same categorical distributions that I used before, but the softmax function converts the unbounded scores into probabilities first. However, with the exploded logit, the error term goes away leading to a more tractable model. This is not the case for the Thurstonian model. The Thurstonian model is more complex, but at the same time we gain more flexibility. With the error term, the Thurstonian model can incorporate the reliability of the participants’ judgments and even correlations, which, as far as I know, can’t be included in the exploded logit model."
  },
  {
    "objectID": "posts/posts/2026-01-06-a-simple-way-to-model-rankings-with-stan/index.html#how-to-cite-this-post",
    "href": "posts/posts/2026-01-06-a-simple-way-to-model-rankings-with-stan/index.html#how-to-cite-this-post",
    "title": "A simple way to model rankings with Stan",
    "section": "How to cite this post",
    "text": "How to cite this post\n\n\n\n\n\n\nCitation\n\n\n\n\n\nBibTeX:\n@misc{nicenboim2026asimplewaytomodelrankingswithstan,\n  author = {Nicenboim, Bruno},\n  title = {A simple way to model rankings with Stan},\n  year = {2026},\n  month = {januari},\n  url = {https://bruno.nicenboim.me/posts/posts/2026-01-07-a-simple-way-to-model-rankings-with-stan/},\n  doi = {10.5281/zenodo.18171805}\n}\nAPA:\nNicenboim, B. (2026, januari 07). A simple way to model rankings with Stan. https://doi.org/10.5281/zenodo.18171805"
  },
  {
    "objectID": "posts/posts/2026-01-06-a-simple-way-to-model-rankings-with-stan/index.html#session-info",
    "href": "posts/posts/2026-01-06-a-simple-way-to-model-rankings-with-stan/index.html#session-info",
    "title": "A simple way to model rankings with Stan",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.5.0 (2025-04-11)\nPlatform: x86_64-pc-linux-gnu\nRunning under: Ubuntu 22.04.5 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0 \nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=nl_NL.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=nl_NL.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=nl_NL.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=nl_NL.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Europe/Amsterdam\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets \n[6] methods   base     \n\nother attached packages:\n[1] bayesplot_1.12.0  cmdstanr_0.9.0    rcorpora_2.0.1   \n[4] extraDistr_1.10.0 ggplot2_3.5.2     tidytable_0.11.2 \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6         jsonlite_2.0.0      \n [3] dplyr_1.1.4          compiler_4.5.0      \n [5] tidyselect_1.2.1     Rcpp_1.1.0          \n [7] stringr_1.5.1        scales_1.4.0        \n [9] yaml_2.3.10          fastmap_1.2.0       \n[11] plyr_1.8.9           R6_2.6.1            \n[13] labeling_0.4.3       generics_0.1.4      \n[15] distributional_0.5.0 knitr_1.50          \n[17] htmlwidgets_1.6.4    backports_1.5.0     \n[19] checkmate_2.3.2      tibble_3.3.0        \n[21] pillar_1.11.1        RColorBrewer_1.1-3  \n[23] posterior_1.6.1      rlang_1.1.6         \n[25] stringi_1.8.7        xfun_0.52           \n[27] cli_3.6.5            withr_3.0.2         \n[29] magrittr_2.0.4       ps_1.9.1            \n[31] processx_3.8.6       digest_0.6.37       \n[33] grid_4.5.0           lifecycle_1.0.4     \n[35] vctrs_0.6.5          tensorA_0.36.2.1    \n[37] evaluate_1.0.3       glue_1.8.0          \n[39] data.table_1.18.0    farver_2.1.2        \n[41] abind_1.4-8          reshape2_1.4.4      \n[43] rmarkdown_2.29       matrixStats_1.5.0   \n[45] tools_4.5.0          pkgconfig_2.0.3     \n[47] htmltools_0.5.8.1"
  },
  {
    "objectID": "posts/posts/2026-01-06-a-simple-way-to-model-rankings-with-stan/index.html#references",
    "href": "posts/posts/2026-01-06-a-simple-way-to-model-rankings-with-stan/index.html#references",
    "title": "A simple way to model rankings with Stan",
    "section": "References",
    "text": "References\n\n\nBarsalou, Lawrence W. 1985. “Ideals, Central Tendency, and Frequency of Instantiation as Determinants of Graded Structure in Categories.” Journal of Experimental Psychology: Learning, Memory, and Cognition 11 (4): 629.\n\n\nBeggs, S, S Cardell, and J Hausman. 1981. “Assessing the Potential Demand for Electric Cars.” Journal of Econometrics 17 (1): 1–19. https://doi.org/https://doi.org/10.1016/0304-4076(81)90056-7.\n\n\nGakis, Konstantinos, Panos Pardalos, Chang-Hwan Choi, Jae-Hyeon Park, and Jiwun Yoon. 2018. “Simulation of a Probabilistic Model for Multi-Contestant Races.” Athens Journal of Sports 5 (2): 95–114.\n\n\nJohnson, Timothy R., and Kristine M. Kuhn. 2013. “Bayesian Thurstonian Models for Ranking Data Using JAGS.” Behavior Research Methods 45 (3): 857–72. https://doi.org/10.3758/s13428-012-0300-3.\n\n\nLee, Michael D., Mark Steyvers, and Brent Miller. 2014. “A Cognitive Model for Aggregating People’s Rankings.” PLOS ONE 9 (5): e96431. https://doi.org/10.1371/journal.pone.0096431.\n\n\nLuce, R. Duncan. 1959. Individual Choice Behavior : A Theoretical Analysis. Book. Wiley N.Y.\n\n\nPlackett, R. L. 1975. “The Analysis of Permutations.” Journal of the Royal Statistical Society. Series C (Applied Statistics) 24 (2): 193–202. http://www.jstor.org/stable/2346567.\n\n\nTalts, Sean, Michael Betancourt, Daniel Simpson, Aki Vehtari, and Andrew Gelman. 2018. “Validating Bayesian Inference Algorithms with Simulation-Based Calibration,” April. http://arxiv.org/abs/1804.06788.\n\n\nThurstone, Louis L. 1927. “A Law of Comparative Judgement.” Psychological Reviews 34: 273–86.\n\n\n———. 1931. “Rank Order as a Psycho-Physical Method.” Journal of Experimental Psychology 14 (3): 187."
  },
  {
    "objectID": "posts/posts/2026-01-06-a-simple-way-to-model-rankings-with-stan/index.html#footnotes",
    "href": "posts/posts/2026-01-06-a-simple-way-to-model-rankings-with-stan/index.html#footnotes",
    "title": "A simple way to model rankings with Stan",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis model is also called the rank ordered logit model (Beggs, Cardell, and Hausman 1981) or Plackett–Luce model due to Plackett (1975) and Luce (1959), but I liked the explosion part more.↩︎"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "CURRICULUM VITAE",
    "section": "",
    "text": "Email:\n[initial].[lastname] [at] tilburguniversity.edu\n\n\nOffice:\nD108, Dante Building, Tilburg University\n\n\nAddress:\nDepartment of Computational Cognitive Science,\n\n\n\nCognitive Science and Artificial Intelligence\n\n\n\nTilburg University\n\n\n\nPO Box 90153\n\n\n\n5000 LE Tilburg\n\n\n\nThe Netherlands"
  },
  {
    "objectID": "cv.html#book",
    "href": "cv.html#book",
    "title": "CURRICULUM VITAE",
    "section": "Book",
    "text": "Book\n\nNicenboim, B., D. J. Schad, and S. Vasishth (2025). Introduction to Bayesian Data Analysis for Cognitive Science. 1st ed. Chapman and Hall/CRC. DOI: 10.1201/9780429342646."
  },
  {
    "objectID": "cv.html#published-or-accepted-in-peer-reviewed-journals",
    "href": "cv.html#published-or-accepted-in-peer-reviewed-journals",
    "title": "CURRICULUM VITAE",
    "section": "Published or accepted in peer-reviewed journals",
    "text": "Published or accepted in peer-reviewed journals\n\nBoelders, S. M., B. Nicenboim, E. Butterbrod, W. De Baene, E. Postma, G. Rutten, L. Ong, and K. Gehring (2025). “Predicting cognitive function three months after surgery in patients with a glioma”. In: Neuro-Oncology Advances, p. vdaf081. ISSN: 2632-2498. DOI: 10.1093/noajnl/vdaf081.\n\n\nDubova, M., S. Chandramouli, G. Gigerenzer, P. Grünwald, W. Holmes, T. Lombrozo, M. Marelli, S. Musslick, B. Nicenboim, L. N. Ross, et al. (2025). “Is Ockham’s razor losing its edge? New perspectives on the principle of model parsimony”. In: Proceedings of the National Academy of Sciences 122.5, p. e2401230121. DOI: 10.1073/pnas.2401230121.\n\n\nBoelders, S. M., B. Nicenboim, E. O. Postma, L. S. Ong, and K. Gehring (2024). “Modeling uncertainty in individual predictions of cognitive functioning for untreated glioma patients using Bayesian regression and clinical variables”. In: Neuro-Oncology 26.Supplement_5, pp. v60-v60. ISSN: 1522-8517. DOI: 10.1093/neuonc/noae144.196.\n\n\nSchad, D. J., B. Nicenboim, and S. Vasishth (2024). “Data aggregation can lead to biased inferences in Bayesian linear mixed models and Bayesian analysis of variance.” In: Psychological Methods. ISSN: 1082-989X. DOI: 10.1037/met0000621.\n\n\nDoorn, J. van, J. M. Haaf, A. M. Stefan, E. Wagenmakers, G. E. Cox, C. P. Davis-Stober, A. Heathcote, D. W. Heck, M. Kalish, D. Kellen, et al. (2023). “Bayes Factors for Mixed Models: a Discussion”. In: Computational Brain & Behavior 6.1, pp. 140-158. ISSN: 2522-087X. DOI: 10.1007/s42113-022-00160-3.\n\n\nVasishth, S., H. Yadav, D. J. Schad, and B. Nicenboim (2023). “Sample Size Determination for Bayesian Hierarchical Models Commonly Used in Psycholinguistics”. In: Computational Brain & Behavior 6.1, pp. 102-126. ISSN: 2522-087X. DOI: 10.1007/s42113-021-00125-y.\n\n\nBen-Artzi, I., Y. Kessler, B. Nicenboim, and N. Shahar (2023). “Computational mechanisms underlying latent inverse value updating of unchosen actions”. In: Science Advances 9.42, p. eadi2704. DOI: 10.1126/sciadv.adi2704.\n\n\nStone, K., B. Nicenboim, S. Vasishth, and F. Rösler (2022). “Understanding the effects of constraint and predictability in ERP”. In: Neurobiology of Language, pp. 1-71. ISSN: 2641-4368. DOI: 10.1162/nol_a_00094.\n\n\nPatterson, C., P. B. Schumacher, B. Nicenboim, J. Hagen, and A. Kehler (2022). “A Bayesian approach to German personal and demonstrative pronouns”. In: Frontiers in Psychology, Language Sciences 12. ISSN: 1664-1078. DOI: 10.3389/fpsyg.2021.672927. eprint: https://www.frontiersin.org/articles/10.3389/fpsyg.2021.672927/abstract.\n\n\nSchad, D. J., B. Nicenboim, P. Bürkner, M. Betancourt, and S. Vasishth (2022). “Workflow Techniques for the Robust Use of Bayes Factors”. In: Psychological methods. ISSN: 1082-989X. DOI: 10.1037/met0000472.\n\n\nAlbert, A. and B. Nicenboim (2022). “Modeling Sonority in Terms of Pitch Intelligibility With the Nucleus Attraction Principle”. In: Cognitive Science 46.7, p. e13161. DOI: doi.or1/cogs.13161.\n\n\nLisson, P., D. Pregla, B. Nicenboim, D. Paape, M. L. van het Nederend, F. Burchert, N. Stadie, D. Caplan, and S. Vasishth (2021). “A computational evaluation of two models of retrieval processes in sentence processing in aphasia”. In: Cognitive Science 45.4. DOI: 10.1111/cogs.12956.\n\n\nNicenboim, B., S. Vasishth, and F. Rösler (2020). “Are words pre-activated probabilistically during sentence comprehension? Evidence from new data and a Bayesian random-effects meta-analysis using publicly available data”. In: Neuropsychologia 142, p. 107427. ISSN: 0028-3932. DOI: 10.1016/j.neuropsychologia.2020.107427.\n\n\nVasishth, S., B. Nicenboim, F. Engelmann, and F. Burchert (2019). “Computational models of retrieval processes in sentence processing”. In: Trends in Cognitive Sciences 23.11, pp. 968 - 982. ISSN: 1364-6613. DOI: 10.1016/j.tics.2019.09.003.\n\n\nNicenboim, B., S. Vasishth, F. Engelmann, and K. Suckow (2018). “Exploratory and confirmatory analyses in sentence processing: A case study of number interference in German”. In: Cognitive Science 42.S4, pp. 1075–1100. DOI: 10.1111/cogs.12589.\n\n\nNicenboim, B., T. B. Roettger, and S. Vasishth (2018). “Using meta-analysis for evidence synthesis: The case of incomplete neutralization in German”. In: Journal of Phonetics 70, pp. 39–55. DOI: 10.1016/j.wocn.2018.06.001.\n\n\nVasishth, S., B. Nicenboim, M. E. Beckman, F. Li, and E. Kong (2018). “Bayesian data analysis in the phonetic sciences: A tutorial introduction”. In: Journal of Phonetics 71, pp. 147–161. DOI: 10.1016/j.wocn.2018.07.008.\n\n\nNicenboim, B. and S. Vasishth (2018). “Models of Retrieval in Sentence Comprehension: A computational evaluation using Bayesian hierarchical modeling”. In: Journal of Memory and Language 99, pp. 1 –34. ISSN: 0749-596X. DOI: 10.1016/j.jml.2017.08.004.\n\n\nPaape, D., B. Nicenboim, and S. Vasishth (2017). “Does antecedent complexity affect ellipsis processing? An empirical investigation”. In: Glossa: A journal of general linguistics. 2.1, p. 71. DOI: 10.5334/gjgl.290.\n\n\nNicenboim, B., P. Logačev, C. Gattei, and S. Vasishth (2016). “When high-capacity readers slow down and low-capacity readers speed up: Working memory and locality effects”. In: Frontiers in Psychology 7.280. ISSN: 1664-1078. DOI: 10.3389/fpsyg.2016.00280.\n\n\nNicenboim, B. and S. Vasishth (2016). “Statistical methods for linguistic research: Foundational Ideas - Part II”. In: Language and Linguistics Compass 10.11, pp. 591–613. ISSN: 1749-818X. DOI: 10.1111/lnc3.12207.\n\n\nVasishth, S. and B. Nicenboim (2016). “Statistical Methods for Linguistic Research: Foundational Ideas - Part I”. In: Language and Linguistics Compass 10.8, pp. 349–369. ISSN: 1749-818X. DOI: 10.1111/lnc3.12201.\n\n\nNicenboim, B., S. Vasishth, C. Gattei, M. Sigman, and R. Kliegl (2015). “Working memory differences in long-distance dependency resolution”. In: Frontiers in Psychology 6.312. ISSN: 1664-1078. DOI: 10.3389/fpsyg.2015.00312."
  },
  {
    "objectID": "cv.html#unpublishedunder-review-manuscripts",
    "href": "cv.html#unpublishedunder-review-manuscripts",
    "title": "CURRICULUM VITAE",
    "section": "Unpublished/Under review manuscripts",
    "text": "Unpublished/Under review manuscripts\n\nNicenboim, B., M. K. van Vugt, R. G. Alhama, B. Anderson, F. Bontje, M. Chimento, S. Columbus, E. S. Dalmaijer, J. Dotlacil, S. M. Østergaard, et al. (2025). “It takes a village to model complex behaviour: A community-based approach”. DOI: 10.31234/osf.io/d2v54_v1.\n\n\nMoorman, S., M. van Elk, E. Vassena, A. Abelmann, F. de Andrade, A. Badura, J. Benichov, N. de Bode, B. Braams, I. Brazil, et al. (2025). “The importance of Brain, Behaviour and Cognition research in changing times and landscapes: Challenges, opportunities and future prospects”. En. DOI: 10.5281/ZENODO.17493166.\n\n\nVasishth, S., B. Nicenboim, N. Chopin, and R. Ryder (2017). “Bayesian hierarchical finite mixture models of reading times: A case study”. DOI: 10.17605/OSF.IO/FWX3S."
  },
  {
    "objectID": "cv.html#short-peer-reviewed-papers-in-conferences",
    "href": "cv.html#short-peer-reviewed-papers-in-conferences",
    "title": "CURRICULUM VITAE",
    "section": "Short peer-reviewed papers in conferences",
    "text": "Short peer-reviewed papers in conferences\n\nNicenboim, B. (2023). “The CoFI Reader: A Continuous Flow of Information approach to modeling reading”. In: MathPsych/ICCM/EMPG. University of Amsterdam, the Netherlands.\n\n\nNicenboim, B. (2018). “The implementation of a model of choice: The (truncated) linear ballistic accumulator”. In: StanCon. Aalto University, Helsinki, Finland. DOI: 10.5281/zenodo.1465990.\n\n\nVasishth, S., N. Chopin, R. Ryder, and B. Nicenboim (2017). “Modelling dependency completion in sentence comprehension as a Bayesian hierarchical mixture process: A case study involving Chinese relative clauses”. In: Proceedings of Cognitive Science Conference. London, UK.\n\n\nVasishth, S., L. Jaeger, and B. Nicenboim (2017). “Feature overwriting as a finite mixture process: Evidence from comprehension data”. In: Proceedings of MathPsych/ICCM Conference. Warwick, UK.\n\n\nNicenboim, B. and S. Vasishth (2017). “Models of Retrieval in Sentence Comprehension”. In: StanCon. (superseeded by 10.1016/j.jml.2017.08.004). Columbia University New York, NY."
  },
  {
    "objectID": "cv.html#contributions-to-open-software",
    "href": "cv.html#contributions-to-open-software",
    "title": "CURRICULUM VITAE",
    "section": "Contributions to open software",
    "text": "Contributions to open software\n\neeguana (https://bruno.nicenboim.me/eeguana/) An R package for tidy-ish manipulation of EEG data. Author\npangoling (https://bruno.nicenboim.me/pangoling/) An R package for estimating the log-probabilities of words in a given context using transformer models. Author\nloo (https://cran.r-project.org/web/packages/loo/). Efficient Leave-One-Out Cross-Validation and WAIC for Bayesian Models. Contributor\nMNE (https://mne.tools/). Open-source Python package for exploring, visualizing, and analyzing human neurophysiological data. Bug fixing\nBayesplot (https://github.com/stan-dev) R package providing an extensive library of plotting functions for use after fitting Bayesian models. Bug fixing"
  },
  {
    "objectID": "cv.html#workshops-and-summer-schools",
    "href": "cv.html#workshops-and-summer-schools",
    "title": "CURRICULUM VITAE",
    "section": "Workshops and summer schools",
    "text": "Workshops and summer schools\n\n\n\n\n\n\n\n2017-2025\n“Advanced Bayesian methods”,\n\n\n\nYearly Summer School on Statistical Methods for Linguistics and Psychology (SMLP),\n\n\n\nUniversity of Potsdam, Germany\n\n\n2020-2021\n“Introduction to computational Bayesian methods using Stan”, Physalia courses,\n\n\n\nBerlin, Germany\n\n\n2020\n“Methods in Advanced Statistics”, with Shravan Vasishth\n\n\n\n2020 Winter School organized by Netherlands Graduate School in Linguistics (LOT),\n\n\n\nTilburg, Netherlands\n\n\n2019\n“Introduction to Bayesian statistics using brms”,\n\n\n\nUniversity of Cologne, Germany\n\n\n2019\n“Introduction to Bayesian statistics using brms”,\n\n\n\nUniversity of Edinburgh, UK\n\n\n2018\nTalk:“Cognitive models of memory processes in sentence comprehension: A case study using Bayesian hierarchical modeling”\n\n\n\nMasterclass in Bayesian Statistics, Research school,\n\n\n\nCIRM (Marseille Luminy, France)\n\n\n2017\n“Introduction to Bayesian Modeling using Stan”,\n\n\n\n13. Tagung der Fachgruppe Methoden und Evaluation der Deutschen Gesellschaft für Psychologie,\n\n\n\nTübingen, Germany"
  },
  {
    "objectID": "cv.html#courses",
    "href": "cv.html#courses",
    "title": "CURRICULUM VITAE",
    "section": "Courses",
    "text": "Courses\n\n\n\n\n\n\n\n2025-2026\nLecturer in “Research Workshop”, BA in Cognitive Science & AI. Tilburg University\n\n\n2022-2025\nLecturer in “Bayesian Multilevel Models/Bayesian Modeling for Data Science”, Master in Data Science & Society. Tilburg University\n\n\n2021-2025\nLecturer in “Bayesian Models of Cognitive Processes”, Master in Cognitive Science & AI. Tilburg University\n\n\n2020-2021\nLecturer in “Research skill: Programing with R”, Data Science & Society. Tilburg University\n\n\n2020-2021\nLecturer in “Methodology for Premasters Data Science & Society”. Tilburg University\n\n\n2015–2017 (Winter)\nLecturer in “Advanced Data Analysis”. University of Potsdam\n\n\n2016 (Summer)\nLecturer in “Predictions in Language Processing”. University of Potsdam\n\n\n2015–2016 (Winter)\nLecturer in “Individual Differences in Sentence Processing”. University of Potsdam\n\n\n2015 (Summer)\nLecturer in “Predictions in Language Processing”. University of Potsdam\n\n\n2008–2010\nTeaching assistant in “Syntax Beginners” and “Foundations of Theoretical Linguistics” Tel Aviv University"
  },
  {
    "objectID": "posts/posts/2026-01-06-welcome-to-my-new-quarto-site/index.html",
    "href": "posts/posts/2026-01-06-welcome-to-my-new-quarto-site/index.html",
    "title": "Welcome to my new Quarto site",
    "section": "",
    "text": "After years of using Hugo, I’ve finally made the switch to Quarto.\nThe main reason? Hugo wasn’t allowing me to update my website anymore!\nThe old posts from my Hugo site are gone (for now), but I’m looking forward to building up new content here. Stay tuned!"
  },
  {
    "objectID": "posts/posts/2026-01-06-welcome-to-my-new-quarto-site/index.html#a-fresh-start",
    "href": "posts/posts/2026-01-06-welcome-to-my-new-quarto-site/index.html#a-fresh-start",
    "title": "Welcome to my new Quarto site",
    "section": "",
    "text": "After years of using Hugo, I’ve finally made the switch to Quarto.\nThe main reason? Hugo wasn’t allowing me to update my website anymore!\nThe old posts from my Hugo site are gone (for now), but I’m looking forward to building up new content here. Stay tuned!"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Posts",
    "section": "",
    "text": "Bayesian ordinal models: A very short practical guide\n\n\n\nStan\n\nBayesian\n\nTutorial\n\nR\n\nbrms\n\n\n\nUnderstanding and setting priors in Bayesian ordinal models with cumulative links\n\n\n\n\n\nJan 9, 2026\n\n\nBruno Nicenboim\n\n\n\n\n\n\n\n\n\n\n\n\nBayesian ordinal models: A very short practical guide\n\n\n\nStan\n\nBayesian\n\nTutorial\n\nR\n\nbrms\n\n\n\nUnderstanding and setting priors in Bayesian ordinal models with cumulative links\n\n\n\n\n\nJan 9, 2026\n\n\nBruno Nicenboim\n\n\n\n\n\n\n\n\n\n\n\n\nA simple way to model rankings with Stan\n\n\n\nStan\n\nBayesian\n\nR\n\nCitable\n\n\n\nHow to fit the exploded logit distribution in Stan to model ranking data\n\n\n\n\n\nJan 7, 2026\n\n\nBruno Nicenboim\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome to my new Quarto site\n\n\n\nMeta\n\nQuarto\n\n\n\n\n\n\n\n\n\nJan 6, 2026\n\n\nBruno Nicenboim\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications.html#section",
    "href": "publications.html#section",
    "title": "Publications & Presentations",
    "section": "2025",
    "text": "2025\n\nBoelders, S. M., B. Nicenboim, E. Butterbrod, W. De Baene, E. Postma, G. Rutten, L. Ong, and K. Gehring (2025). “Predicting cognitive function three months after surgery in patients with a glioma”. In: Neuro-Oncology Advances, p. vdaf081. ISSN: 2632-2498. DOI: 10.1093/noajnl/vdaf081. [eprint] [read] [bib]\n\n\nDubova, M., S. Chandramouli, G. Gigerenzer, P. Grünwald, W. Holmes, T. Lombrozo, M. Marelli, S. Musslick, B. Nicenboim, L. N. Ross, et al. (2025). “Is Ockham’s razor losing its edge? New perspectives on the principle of model parsimony”. In: Proceedings of the National Academy of Sciences 122.5, p. e2401230121. DOI: 10.1073/pnas.2401230121. [eprint] [read] [bib]"
  },
  {
    "objectID": "publications.html#section-1",
    "href": "publications.html#section-1",
    "title": "Publications & Presentations",
    "section": "2024",
    "text": "2024\n\nBoelders, S. M., B. Nicenboim, E. O. Postma, L. S. Ong, and K. Gehring (2024). “Modeling uncertainty in individual predictions of cognitive functioning for untreated glioma patients using Bayesian regression and clinical variables”. In: Neuro-Oncology 26.Supplement_5, pp. v60-v60. ISSN: 1522-8517. DOI: 10.1093/neuonc/noae144.196. [eprint] [read] [bib]\n\n\nSchad, D. J., B. Nicenboim, and S. Vasishth (2024). “Data aggregation can lead to biased inferences in Bayesian linear mixed models and Bayesian analysis of variance.” In: Psychological Methods. ISSN: 1082-989X. DOI: 10.1037/met0000621. [bib]"
  },
  {
    "objectID": "publications.html#section-2",
    "href": "publications.html#section-2",
    "title": "Publications & Presentations",
    "section": "2023",
    "text": "2023\n\nDoorn, J. van, J. M. Haaf, A. M. Stefan, E. Wagenmakers, G. E. Cox, C. P. Davis-Stober, A. Heathcote, D. W. Heck, M. Kalish, D. Kellen, et al. (2023). “Bayes Factors for Mixed Models: a Discussion”. In: Computational Brain & Behavior 6.1, pp. 140-158. ISSN: 2522-087X. DOI: 10.1007/s42113-022-00160-3. [eprint] [bib]\n\n\nVasishth, S., H. Yadav, D. J. Schad, and B. Nicenboim (2023). “Sample Size Determination for Bayesian Hierarchical Models Commonly Used in Psycholinguistics”. In: Computational Brain & Behavior 6.1, pp. 102-126. ISSN: 2522-087X. DOI: 10.1007/s42113-021-00125-y. [eprint] [bib]\n\n\nBen-Artzi, I., Y. Kessler, B. Nicenboim, and N. Shahar (2023). “Computational mechanisms underlying latent inverse value updating of unchosen actions”. In: Science Advances 9.42, p. eadi2704. DOI: 10.1126/sciadv.adi2704. [eprint] [bib]"
  },
  {
    "objectID": "publications.html#section-3",
    "href": "publications.html#section-3",
    "title": "Publications & Presentations",
    "section": "2022",
    "text": "2022\n\nStone, K., B. Nicenboim, S. Vasishth, and F. Rösler (2022). “Understanding the effects of constraint and predictability in ERP”. In: Neurobiology of Language, pp. 1-71. ISSN: 2641-4368. DOI: 10.1162/nol_a_00094. [eprint] [code/data] [bib]\n\n\nPatterson, C., P. B. Schumacher, B. Nicenboim, J. Hagen, and A. Kehler (2022). “A Bayesian approach to German personal and demonstrative pronouns”. In: Frontiers in Psychology, Language Sciences 12. ISSN: 1664-1078. DOI: 10.3389/fpsyg.2021.672927. eprint: https://www.frontiersin.org/articles/10.3389/fpsyg.2021.672927/abstract. [eprint] [bib]\n\n\nSchad, D. J., B. Nicenboim, P. Bürkner, M. Betancourt, and S. Vasishth (2022). “Workflow Techniques for the Robust Use of Bayes Factors”. In: Psychological methods. ISSN: 1082-989X. DOI: 10.1037/met0000472. [eprint] [code/data] [bib]\n\n\nAlbert, A. and B. Nicenboim (2022). “Modeling Sonority in Terms of Pitch Intelligibility With the Nucleus Attraction Principle”. In: Cognitive Science 46.7, p. e13161. DOI: doi.or1/cogs.13161. [eprint] [code/data] [bib]"
  },
  {
    "objectID": "publications.html#section-4",
    "href": "publications.html#section-4",
    "title": "Publications & Presentations",
    "section": "2021",
    "text": "2021\n\nLisson, P., D. Pregla, B. Nicenboim, D. Paape, M. L. van het Nederend, F. Burchert, N. Stadie, D. Caplan, and S. Vasishth (2021). “A computational evaluation of two models of retrieval processes in sentence processing in aphasia”. In: Cognitive Science 45.4. DOI: 10.1111/cogs.12956. [eprint] [bib]"
  },
  {
    "objectID": "publications.html#section-5",
    "href": "publications.html#section-5",
    "title": "Publications & Presentations",
    "section": "2020",
    "text": "2020\n\nNicenboim, B., S. Vasishth, and F. Rösler (2020). “Are words pre-activated probabilistically during sentence comprehension? Evidence from new data and a Bayesian random-effects meta-analysis using publicly available data”. In: Neuropsychologia 142, p. 107427. ISSN: 0028-3932. DOI: 10.1016/j.neuropsychologia.2020.107427. [eprint] [bib]"
  },
  {
    "objectID": "publications.html#section-6",
    "href": "publications.html#section-6",
    "title": "Publications & Presentations",
    "section": "2019",
    "text": "2019\n\nVasishth, S., B. Nicenboim, F. Engelmann, and F. Burchert (2019). “Computational models of retrieval processes in sentence processing”. In: Trends in Cognitive Sciences 23.11, pp. 968 - 982. ISSN: 1364-6613. DOI: 10.1016/j.tics.2019.09.003. [eprint] [bib]"
  },
  {
    "objectID": "publications.html#section-7",
    "href": "publications.html#section-7",
    "title": "Publications & Presentations",
    "section": "2018",
    "text": "2018\n\nNicenboim, B., S. Vasishth, F. Engelmann, and K. Suckow (2018). “Exploratory and confirmatory analyses in sentence processing: A case study of number interference in German”. In: Cognitive Science 42.S4, pp. 1075–1100. DOI: 10.1111/cogs.12589. [eprint] [code/data] [bib]\n\n\nNicenboim, B., T. B. Roettger, and S. Vasishth (2018). “Using meta-analysis for evidence synthesis: The case of incomplete neutralization in German”. In: Journal of Phonetics 70, pp. 39–55. DOI: 10.1016/j.wocn.2018.06.001. [eprint] [code/data] [bib]\n\n\nVasishth, S., B. Nicenboim, M. E. Beckman, F. Li, and E. Kong (2018). “Bayesian data analysis in the phonetic sciences: A tutorial introduction”. In: Journal of Phonetics 71, pp. 147–161. DOI: 10.1016/j.wocn.2018.07.008. [eprint] [code/data] [bib]\n\n\nNicenboim, B. and S. Vasishth (2018). “Models of Retrieval in Sentence Comprehension: A computational evaluation using Bayesian hierarchical modeling”. In: Journal of Memory and Language 99, pp. 1 –34. ISSN: 0749-596X. DOI: 10.1016/j.jml.2017.08.004. [eprint] [code/data] [bib]"
  },
  {
    "objectID": "publications.html#section-8",
    "href": "publications.html#section-8",
    "title": "Publications & Presentations",
    "section": "2017",
    "text": "2017\n\nPaape, D., B. Nicenboim, and S. Vasishth (2017). “Does antecedent complexity affect ellipsis processing? An empirical investigation”. In: Glossa: A journal of general linguistics. 2.1, p. 71. DOI: 10.5334/gjgl.290. [eprint] [bib]"
  },
  {
    "objectID": "publications.html#section-9",
    "href": "publications.html#section-9",
    "title": "Publications & Presentations",
    "section": "2016",
    "text": "2016\n\nNicenboim, B., P. Logačev, C. Gattei, and S. Vasishth (2016). “When high-capacity readers slow down and low-capacity readers speed up: Working memory and locality effects”. In: Frontiers in Psychology 7.280. ISSN: 1664-1078. DOI: 10.3389/fpsyg.2016.00280. [eprint] [code/data] [bib]\n\n\nNicenboim, B. and S. Vasishth (2016). “Statistical methods for linguistic research: Foundational Ideas - Part II”. In: Language and Linguistics Compass 10.11, pp. 591–613. ISSN: 1749-818X. DOI: 10.1111/lnc3.12207. [eprint] [bib]\n\n\nVasishth, S. and B. Nicenboim (2016). “Statistical Methods for Linguistic Research: Foundational Ideas - Part I”. In: Language and Linguistics Compass 10.8, pp. 349–369. ISSN: 1749-818X. DOI: 10.1111/lnc3.12201. [eprint] [bib]"
  },
  {
    "objectID": "publications.html#section-10",
    "href": "publications.html#section-10",
    "title": "Publications & Presentations",
    "section": "2015",
    "text": "2015\n\nNicenboim, B., S. Vasishth, C. Gattei, M. Sigman, and R. Kliegl (2015). “Working memory differences in long-distance dependency resolution”. In: Frontiers in Psychology 6.312. ISSN: 1664-1078. DOI: 10.3389/fpsyg.2015.00312. [eprint] [code/data] [bib]"
  },
  {
    "objectID": "team.html",
    "href": "team.html",
    "title": "Team",
    "section": "",
    "text": "Together with Giovanni Cassani, I am the PI of the Computational Psycholinguistics Lab.\nMy current team is the following:"
  },
  {
    "objectID": "team.html#phd-student",
    "href": "team.html#phd-student",
    "title": "Team",
    "section": "Phd Student",
    "text": "Phd Student\n\n\n\n\n\nSara Møller Østergaard"
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/index.html",
    "href": "posts/posts/2026-01-09-ordinal-models/index.html",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "",
    "text": "I’ll first load some R packages that will be useful throughout this post.\nlibrary(extraDistr)\nlibrary(tidytable)\nlibrary(ggplot2)\nlibrary(brms)\nlibrary(bayesplot)\nlibrary(patchwork)\nlibrary(ggridges)\n\ntheme_set(theme_minimal(base_size = 14))"
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/index.html#introduction",
    "href": "posts/posts/2026-01-09-ordinal-models/index.html#introduction",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Introduction",
    "text": "Introduction\nThis post explains some nuances of Bayesian ordinal regression with cumulative links and focuses on how to set sensible priors. These models are appropriate for modeling data where the dependent variables are ordered responses without meaningful metric distances, such as Likert scales. The presentation builds on Bürkner and Vuorre (2019), but restricts attention to cumulative models."
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/index.html#the-cumulative-link-framework",
    "href": "posts/posts/2026-01-09-ordinal-models/index.html#the-cumulative-link-framework",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "The cumulative link framework",
    "text": "The cumulative link framework\nA cumulative link model assumes an underlying continuous latent variable (typically with a normal or logistic distribution) and a set of thresholds \\(\\tau_1, \\ldots, \\tau_K\\) that partition this scale. An observation falls in category \\(k\\) if the latent value, a random variable \\(\\tilde Y\\), lies between \\(\\tau_{k-1}\\) and \\(\\tau_k\\), with \\(\\tau_0 = -\\infty\\) and \\(\\tau_{K+1} = +\\infty\\).\n\nA concrete example\nConsider a 5-point Likert scale assessing understanding of Bayesian statistics with options: “nothing,” “a little,” “more or less,” “something,” and “everything.” This scale requires 4 thresholds. The probability for each category corresponds to the area between:\n\nCategory 1 (“nothing”): \\(-\\infty\\) to \\(\\tau_1\\)\nCategory 2 (“a little”): \\(\\tau_1\\) to \\(\\tau_2\\)\nCategory 3 (“more or less”): \\(\\tau_2\\) to \\(\\tau_3\\)\nCategory 4 (“something”): \\(\\tau_3\\) to \\(\\tau_4\\)\nCategory 5 (“everything”): \\(\\tau_4\\) to \\(+\\infty\\)\n\nLet’s visualize this with specific threshold values for a logistic distribution1. We make up the following thresholds\n\nthres &lt;- c(-2, -1, 1.5, 3)\n\n\n\nCode\ncategory &lt;- factor(1:5, labels = c(\"Nothing\", \"A little\", \"More or less\", \n                                     \"Something\", \"Everything\"))\n  \nx_vals &lt;- seq(-6, 6, length.out = 500)\nnorm_data &lt;- data.frame(\n  x = x_vals,\n  y = dlogis(x_vals)\n)\n\ncategory_positions &lt;- c(-Inf, thres, Inf)\ncategory_midpoints &lt;- (category_positions[-1] + category_positions[-length(category_positions)]) / 2\ncategory_midpoints[1] &lt;- max(-6, category_midpoints[1])\ncategory_midpoints[5] &lt;- min(6, category_midpoints[5])\n\nthreshold_labels &lt;- data.frame(\n  x = thres,\n  y = dlogis(thres) + 0.02,\n  label = paste0(\"τ[\", 1:4, \"]\")\n)\n\ncategory_labels &lt;- data.frame(\n  x = category_midpoints,\n  y = 0.02,\n  label = as.character(category)\n)\n\np1 &lt;- ggplot(norm_data, aes(x = x, y = y)) +\n  geom_line(linewidth = 1, color = \"steelblue\") +\n  geom_vline(xintercept = thres, linetype = \"dashed\", color = \"red\", linewidth = 0.8) +\n  geom_text(data = threshold_labels, aes(x = x, y = y, label = label),\n            parse = TRUE, size = 4.5, color = \"red\", hjust = -0.2, vjust = 0) +\n  geom_text(data = category_labels, aes(x = x, y = y, label = label),\n            size = 3.5, color = \"black\", hjust = 0.5) +\n  labs(title = \"Standard Logistic Distribution with Thresholds\",\n       x = \"Latent Variable\",\n       y = \"Density\") +\n  theme_minimal(base_size = 12)\n\nprint(p1)\n\n\n\n\n\n\n\n\n\n\n\nComputing category probabilities\nNow let’s calculate the probability mass between each threshold:\n\nprobs &lt;- diff(plogis(c(-Inf, thres, Inf)))\n\n# This above is just a more general case than:\n# probs &lt;- c(\n#   plogis(thres[1]),  # P(Y = 1)\n#   plogis(thres[2]) - plogis(thres[1]),  # P(Y = 2)\n#   plogis(thres[3]) - plogis(thres[2]),  # P(Y = 3)\n#   plogis(thres[4]) - plogis(thres[3]),  # P(Y = 4)\n#   1 - plogis(thres[4])  # P(Y = 5)\n# )\n\nprob_data &lt;- data.frame(\n  category = category,\n  probability = probs\n)\n\nprob_data\n\n      category probability\n1      Nothing  0.11920292\n2     A little  0.14973850\n3 More or less  0.54863305\n4    Something  0.13499965\n5   Everything  0.04742587\n\n\n\n\nCode\nggplot(prob_data, aes(x = category, y = probability, fill = category)) +\n  geom_col(alpha = 0.7, color = \"black\") +\n  scale_fill_brewer(palette = \"Blues\") +\n  labs(title = \"Category Probabilities (Baseline)\",\n       x = \"Understanding Level\",\n       y = \"Probability\") +\n  theme_minimal(base_size = 12) +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  ylim(0, 1)\n\n\n\n\n\n\n\n\n\nWe observe that the middle category (“more or less”) receive the highest probability mass.\n\n\nThe effect of shifting thresholds\nNow, let’s examine what happens when we shift all thresholds to the right by one unit and a half: simulating less understanding across the board.\n\nthres &lt;- thres + 1.5\n\n\n\n\n\n\n\n\n\n\n\n\n      category probability\n1      Nothing  0.37754067\n2     A little  0.24491866\n3 More or less  0.33011480\n4    Something  0.03643893\n5   Everything  0.01098694\n\n\n\n\n\n\n\n\n\nNotice how shifting the thresholds rightward decreases the probability of higher categories (more understanding) while increasing the probability of lower categories."
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/index.html#modeling-an-intervention-effect",
    "href": "posts/posts/2026-01-09-ordinal-models/index.html#modeling-an-intervention-effect",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Modeling an intervention effect",
    "text": "Modeling an intervention effect\nIn an ordinal regression with a cumulative link, our goal is to understand how a latent variable \\(\\tilde Y\\) shifts based on predictors or interventions. Suppose we want to assess how reading a book about Bayesian modeling2 affects responses to our understanding question.\n\nSimulating data\nLet’s generate synthetic data to illustrate this. We’ll simulate a group of students before and after reading our book.\nThis type of model assumes that, underlyingly, there is a continuous latent “rating”, and we specify a regression on this latent variable \\(\\tilde Y\\) that determines how the response categories are affected by our manipulation (note that there is no intercept here; the thresholds will later act as something close to intercepts for each category):\n\\[ \\tilde Y = \\eta + \\epsilon \\]\nwith\n\\[\\eta = \\beta \\cdot \\text{read}\\]\nwhere \\(\\text{read} \\in \\{0,1\\}\\) is a treatment indicator (in more realistic settings, one may prefer richer contrast coding; see Chapter 6 of Nicenboim, Schad, and Vasishth (2025)).\nIn principle, one could allow the predictor to have category-specific effects by estimating regressions for each threshold. However, Bürkner and Vuorre (2019) argue that while this parameterization is unproblematic for some ordinal models (such as sequential or adjacent-category models), it can lead to difficulties in model fitting for cumulative models.\nTo move from the continuous latent variable \\(\\tilde Y\\) to a discrete response, we define the observed outcome as follows:\n\\[Y = k \\quad \\text{if} \\quad \\tau_{k-1} &lt; \\tilde Y \\le \\tau_k\\] with boundary conditions \\(\\tau_0 = -\\infty\\) and \\(\\tau_{K+1} = +\\infty\\).\nWe keep the \\(k\\) thresholds (\\(\\tau_k\\)) defined above as the default cutoff points (brms refers to these as intercepts, though note the difference in sign convention below).\nGiven a cumulative link, the probability of observing category \\(k\\) is\n\\[\\Pr(Y = k \\mid \\text{read}) = F(\\tau_k - \\eta) - F(\\tau_{k-1} - \\eta)\\]\nHere, \\(F\\) denotes the cumulative distribution function of the error term \\(\\epsilon\\) of \\(\\tilde Y\\). We assume a logistic distribution for computational convenience, which yields a logistic cumulative link (assuming a normal distribution would lead to a probit link, with otherwise very similar expressions).\nThus, under a logistic cumulative link, the probability of observing category \\(k\\) is\n\\[\\Pr(Y = k \\mid \\text{read}) = \\operatorname{logit}^{-1}(\\tau_k - \\eta) - \\operatorname{logit}^{-1}(\\tau_{k-1} - \\eta)\\]\nwhere \\(\\operatorname{logit}^{-1}\\) denotes the CDF of the logistic distribution (available in R via plogis()). Notice that the regression term, \\(\\eta\\), is subtracted from each threshold.\nTo simulate data from this model, we treat the resulting category probabilities as defining a categorical distribution and sample responses accordingly:\n\\[Y \\sim \\text{Categorical}\\!\\left( \\Pr(Y=1), \\ldots, \\Pr(Y=K) \\right)\\]\nOne important insight is that \\(\\beta\\) affects all categories equally: when \\(\\beta &gt; 0\\), \\(\\tilde Y\\) increases, increasing the probability of higher response categories at the expense of lower response categories; when \\(\\beta &lt; 0\\), \\(\\tilde Y\\) decreases, increasing the probability of lower categories at the expense of higher response categories.\nIn the following simulation, we use the last thres values we defined (-0.5, 0.5, 3, 4.5) as the cutoff points of the model (\\(\\tau_k\\); called intercepts in brms), and we assume that reading increases \\(\\eta\\) (and also \\(\\tilde Y\\) on average) by \\(1.5\\). We generate data from 1000 participants before and after reading our book:\n\nset.seed(123)\n\nN &lt;- 1000\ntau &lt;- thres\nbeta &lt;- 1.5\neta_noread &lt;- 0 * beta\neta_read  &lt;- 1 * beta\n\ndf_sim &lt;- data.frame(\n  read = rep(c(0, 1), each = N),\n  category = c(\n    rcat(N, diff(plogis(c(-Inf, tau - eta_noread, Inf))), labels = category),\n    rcat(N, diff(plogis(c(-Inf, tau - eta_read, Inf))), labels = category)\n  )\n) |&gt;\n  mutate(response = as.numeric(category))\n\n# Display summary statistics\ntable(df_sim$read, df_sim$category)\n\n   \n    Nothing A little More or less Something Everything\n  0     382      238          329        40         11\n  1     114      154          549       138         45\n\n\nLet’s visualize the distribution of responses in both groups:\n\n\nCode\nggplot(df_sim, aes(x = response, fill = factor(read, labels = c(\"Before reading\", \"After reading\")), \n                   group = factor(read))) +\n  geom_bar(position = \"dodge\", alpha = 0.7, color = \"black\") +\n  scale_fill_manual(values = c(\"Before reading\" = \"coral\", \"After reading\" = \"forestgreen\")) +\n  labs(title = \"Distribution of Responses\",\n       x = \"Understanding Level\",\n       y = \"Count\",\n       fill = \"Group\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n\nNow that we have (simulated) data, let’s fit it with brms."
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/index.html#understanding-priors-for-ordinal-models",
    "href": "posts/posts/2026-01-09-ordinal-models/index.html#understanding-priors-for-ordinal-models",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Understanding priors for ordinal models",
    "text": "Understanding priors for ordinal models\nWhen fitting ordinal regression models with brms, we need to specify priors for (at least):\n\n“Intercepts” which in fact are thresholds or cutoff points\nRegression coefficients\n\nIn brms, the thresholds are automatically constrained to be ordered (\\(\\tau_1 &lt; \\tau_2 &lt; \\ldots &lt; \\tau_K\\)).\n\nWhy tight priors concentrate probability on extremes\nLet’s start by examining an intercept-only model with tight priors on the thresholds:\n\npriors_tight &lt;- c(\n  prior(normal(0, 0.5), class = \"Intercept\")\n)\n\nWith normal(0, 0.5) priors, all thresholds are pulled toward zero with relatively little spread. This concentrates the thresholds in a narrow region. This means that when thresholds cluster tightly around zero, most of the latent distribution’s mass falls outside the middle thresholds: either far below \\(\\tau_1\\) or far above \\(\\tau_K\\). This assigns most probability to extreme categories (the first and last).\n\nfit_prior_tight &lt;- brm(\n  response ~ 1,\n  data = df_sim,\n  family = cumulative(),\n  prior = priors_tight,\n  sample_prior = \"only\",\n  cores = 4,\n  seed = 123,\n  refresh = 0,\n  control = list(adapt_delta = 0.9) # avoid divergent transitions\n)\n\nWe define a visualization function ppd_lineplot() to inspect prior predictions.\n\n\nCode\nppd_lineplot &lt;- function(ypred, title = \"Prior Predictive Distribution\",\n                          subtitle = NULL) {\n  max_level &lt;- max(ypred) \n  proportions_per_draw &lt;- lapply(1:nrow(ypred), function(i) {\n    props &lt;- table(factor(ypred[i, ], levels = 1:max_level)) / ncol(ypred)\n    data.frame(\n      draw = i,\n      response = 1:max_level,\n      proportion = as.numeric(props)\n    )\n  })\n  ppd_data &lt;- do.call(rbind, proportions_per_draw)\n\n  # Add beeswarm-like jitter: horizontal offset based on density\n  ppd_data &lt;- ppd_data |&gt;\n    group_by(response) |&gt;\n    mutate(\n      prop_bin = round(proportion, 2)\n    ) |&gt;\n    group_by(response, prop_bin) |&gt;\n    mutate(\n      n_at_prop = n(),\n      rank_at_prop = row_number() - (n() + 1) / 2,\n      # Horizontal jitter proportional to local density\n      x_jitter = response + rank_at_prop * 0.3 / max(n_at_prop, 1)\n    ) |&gt;\n    ungroup()\n\n  ggplot(ppd_data, aes(x = x_jitter, y = proportion)) +\n    geom_line(aes(group = draw), alpha = 0.1, color = \"steelblue\") +\n    geom_point(alpha = 0.4, color = \"steelblue\", size = 1) +\n    geom_hline(yintercept = 0.2, linetype = \"dashed\", color = \"gray40\") +\n    scale_x_continuous(breaks = 1:5, labels = 1:5) +\n    scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +\n    labs(title = title,\n         subtitle = subtitle,\n         x = \"Response Category\",\n         y = \"Proportion\") +\n    theme_minimal(base_size = 12)\n}\n\n\n\nypred_prior_tight &lt;- posterior_predict(fit_prior_tight, ndraws = 200)\nppd_lineplot(ypred_prior_tight,\n              title = \"Prior Predictive Distribution: Tight Priors (SD = 0.5)\",\n              subtitle = \"Most probability mass concentrated in extreme categories\")\n\n\n\n\n\n\n\n\nWith tight priors, the model tends to predict extreme responses, as the thresholds cluster near zero and don’t span the full range of the latent distribution.\n\n\nIntercept-only model: Medium priors\nNow let’s use more dispersed priors:\n\npriors_medium &lt;- c(\n  prior(normal(0, 3), class = \"Intercept\")\n)\n\nWith normal(0, 3) priors, the thresholds can spread out more widely across the latent scale. This means the middle thresholds are more likely to be well-separated, capturing more of the distribution’s central mass and leading to more balanced predictions across all categories.\n\nfit_prior_medium &lt;- brm(\n  response ~ 1,\n  data = df_sim,\n  family = cumulative(),\n  prior = priors_medium,\n  sample_prior = \"only\",\n  cores = 4,\n  seed = 123,\n  refresh = 0\n)\n\n\nypred_prior_medium &lt;- posterior_predict(fit_prior_medium, ndraws = 200)\nppd_lineplot(ypred_prior_medium,\n              title = \"Prior Predictive Distribution: Medium Priors (SD = 3)\",\n              subtitle = \"More balanced distribution across categories\")\n\n\n\n\n\n\n\n\n\n\nIntercept-only model: Diffuse priors\nLet’s examine very diffuse priors:\n\npriors_diffuse &lt;- c(\n  prior(normal(0, 10), class = \"Intercept\")\n)\n\nfit_prior_diffuse &lt;- brm(\n  response ~ 1,\n  data = df_sim,\n  family = cumulative(),\n  prior = priors_diffuse,\n  sample_prior = \"only\",\n  cores = 4,\n  seed = 123,\n  refresh = 0,\n  control = list(adapt_delta = 0.9)\n)\n\n\nypred_prior_diffuse &lt;- posterior_predict(fit_prior_diffuse, ndraws = 200)\nppd_lineplot(ypred_prior_diffuse, \n              title = \"Prior Predictive Distribution: Diffuse Priors (SD = 10)\",\n       subtitle = \"Very flat distribution - least informative\")\n\n\n\n\n\n\n\n\nVery diffuse priors allow thresholds to be extremely spread out, often resulting in a very sparse distribution across categories.\n\n\nIntercept-only model: Nudging priors\nWe might have substantive information suggesting most people start as beginners. We can encode this by centering the threshold prior at a positive value:\n\npriors_mid_inf &lt;- c(\n  prior(normal(1, 3), class = \"Intercept\")\n)\n\nfit_mid_inf &lt;- brm( \n  response ~ 1,\n  data = df_sim,\n  family = cumulative(),\n  prior = priors_mid_inf,\n  sample_prior = \"only\",\n  cores = 4,\n  seed = 123,\n  refresh = 0\n)\n\n\nypred_mid_inf &lt;- posterior_predict(fit_mid_inf, ndraws = 200)\nppd_lineplot(ypred_mid_inf, \n              title = \"Prior Predictive Distribution: Nudged Priors (Mean = 1, SD = 3)\",\n       subtitle = \"Prior belief that lower understanding is more common\")\n\n\n\n\n\n\n\n\nBy centering the threshold prior at 1 instead of 0, we shift thresholds rightward, making lower categories more probable a priori.\n\n\nBetter priors?\n\n(taus &lt;- qlogis(seq(.2,from=0.2, to = 0.8)))\n\n#priors_better &lt;- c(\n#  prior_string(paste0(\"normal(\",taus,\", 3)\"), class = \"Intercept\", coef = 1:4)\n#)\n\npriors_better &lt;- c(\n  prior(normal(-1.39, 3), class = Intercept, coef = 1),\n  prior(normal(-0.41, 3), class = Intercept, coef = 2),\n  prior(normal(0.41, 3), class = Intercept, coef = 3),\n  prior(normal(-.39, 3), class = Intercept, coef = 4)\n)\n\n\n\nfit_better &lt;- brm( \n  response ~ 1,\n  data = df_sim,\n  family = cumulative(),\n  prior = priors_better,\n  sample_prior = \"only\",\n  cores = 4,\n  seed = 123,\n  refresh = 0,\n  control = list(adapt_delta = 0.9)\n)\n\nWarning: The global prior 'student_t(3, 0, 2.5)' of class 'Intercept' will not\nbe used in the model as all related coefficients have individual priors\nalready. If you did not set those priors yourself, then maybe brms has assigned\ndefault priors. See ?set_prior and ?default_prior for more details.\n\n\n\nfit_better |&gt; get_prior()\n\n                prior     class coef group resp dpar nlpar lb ub tag\n student_t(3, 0, 2.5) Intercept                                     \n student_t(3, 0, 2.5) Intercept    1                                \n student_t(3, 0, 2.5) Intercept    2                                \n student_t(3, 0, 2.5) Intercept    3                                \n student_t(3, 0, 2.5) Intercept    4                                \n       source\n      default\n (vectorized)\n (vectorized)\n (vectorized)\n (vectorized)\n\n\n\nypred_better &lt;- posterior_predict(fit_better, ndraws = 200)\nppd_lineplot(ypred_mid_inf, \n              title = \"Prior Predictive Distribution: \",\n       subtitle = \"\")\n\n\n\n\n\n\n\n\n\n\nPrior predictive distribution for the slope\nLet’s also examine what our prior beliefs about the treatment effect imply:\n\npriors_full &lt;- c(\n  prior(normal(0, 3), class = \"Intercept\"),\n  prior(normal(0, 1.5), class = \"b\")\n)\n\nfit_slope_prior &lt;- brm(\n  response ~ read,\n  data = df_sim,\n  family = cumulative(),\n  prior = priors_full,\n  sample_prior = \"only\",\n  cores = 4,\n  seed = 123,\n  refresh = 0,\n  control = list(adapt_delta = 0.9)\n)\n\n\nypred_slope_prior &lt;- posterior_predict(fit_slope_prior, ndraws = 200)\nypred_noread &lt;- ypred_slope_prior[, 1:1000]\nypred_read &lt;- ypred_slope_prior[, 1001:2000]\nypred_diff &lt;- abs(ypred_noread - ypred_read)\nppd_lineplot(ypred_diff,\n              title = \"Prior Predictive Distribution: Full Model with Slope Prior\",\n       subtitle = \"normal(0, 1.5) prior on treatment effect\")\n\n\n\n\n\n\n\n\nThe prior normal(0, 1.5) on the slope is weakly informative: it allows for moderate effects in either direction while gently regularizing against implausibly large effects.\n\n\nFitting to the simulated data\nNow let’s fit the model to our simulated data:\n\nfit_full &lt;- brm(\n  response ~ read,\n  data = df_sim,\n  family = cumulative(),\n  prior = priors_full,\n  cores = 4,\n  seed = 123,\n  warmup = 1000,\n  iter = 2000,\n  refresh = 0\n)\n\n\nfit_full\n\n Family: cumulative \n  Links: mu = logit \nFormula: response ~ read \n   Data: df_sim (Number of observations: 2000) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]    -0.50      0.06    -0.62    -0.38 1.00     4501     3153\nIntercept[2]     0.50      0.06     0.37     0.62 1.00     4802     3359\nIntercept[3]     2.98      0.09     2.79     3.16 1.00     3939     3068\nIntercept[4]     4.55      0.15     4.26     4.85 1.00     3991     2905\nread             1.50      0.09     1.32     1.66 1.00     3854     2924\n\nFurther Distributional Parameters:\n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nIf this were real data, based on the read coefficient, we would conclude that reading our book affects understanding. The positive coefficient read ≈ 1.5 indicates that reading makes higher categories (more understanding) more probable.\n\n\nInterpreting predicted probabilities\nTo understand what the model estimates mean in practical terms, let’s examine the predicted probabilities:\n\n\nCode\nce &lt;- conditional_effects(fit_full, effects = \"read\", categorical = TRUE)\n\nplot(ce, plot = FALSE)[[1]] +\n  scale_fill_brewer(palette = \"RdYlGn\", direction = 1) +\n  labs(title = \"Predicted Response Probabilities by Reading Status\",\n       subtitle = \"Model predictions with 95% credible intervals\",\n       x = \"Read Book\",\n       y = \"Predicted Probability\",\n       fill = \"response\") +\n  theme_minimal(base_size = 12) +\n  theme(legend.position = \"right\")\n\n\n\n\n\n\n\n\n\nThe conditional effects plot shows how reading the book shifts the entire distribution toward higher understanding categories. Before reading (read = 0), lower categories have higher probabilities; after reading (read = 1), the distribution shifts substantially toward “something” and “everything.”\nWe can also examine specific fitted values:\n\n\nCode\nnew_data &lt;- data.frame(read = c(0, 1))\nfitted_probs &lt;- fitted(fit_full, newdata = new_data)\n\nfitted_df &lt;- data.frame(\n  read = rep(c(\"Before\", \"After\"), each = 5),\n  category = rep(1:5, times = 2),\n  probability = c(fitted_probs[1, \"Estimate\", ], fitted_probs[2, \"Estimate\",]),\n  lower = c(fitted_probs[1, \"Q2.5\",], fitted_probs[2 , \"Q2.5\",]),\n  upper = c(fitted_probs[1, \"Q97.5\",], fitted_probs[2 , \"Q97.5\",])\n)\n\nggplot(fitted_df, aes(x = factor(category), y = probability, fill = read)) +\n  geom_col(position = \"dodge\", alpha = 0.7, color = \"black\") +\n  geom_errorbar(aes(ymin = lower, ymax = upper), \n                position = position_dodge(0.9), width = 0.2) +\n  scale_fill_manual(values = c(\"Before\" = \"coral\", \"After\" = \"forestgreen\")) +\n  labs(title = \"Model-Predicted Probabilities with 95% Credible Intervals\",\n       x = \"Understanding Category\",\n       y = \"Predicted Probability\",\n       fill = \"Reading Status\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n\nThe fitted probabilities show concrete estimates: for instance, before reading, the probability of responding “nothing” is about 0.38, whereas after reading it drops to about 0.12. Conversely, the probability of responding “everything” increases from about 0.01 to 0.05.\n\n\nPosterior predictive check\nFinally, let’s verify that the model fits the observed data well:\n\npp_check(fit_full, type = \"bars\", ndraws = 100) +\n  labs(title = \"Posterior Predictive Check: Full Model\",\n       subtitle = \"Model predictions compared to observed data\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\nThe posterior predictive distribution closely matches the observed data patterns, indicating good model fit."
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/index.html#recovery-of-the-parameters",
    "href": "posts/posts/2026-01-09-ordinal-models/index.html#recovery-of-the-parameters",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Recovery of the parameters",
    "text": "Recovery of the parameters\nLet’s examine whether the model successfully recovered the true parameters we used to generate the data. We simulated with thresholds \\(\\tau = [-0.5, 0.5, 3, 4.5]\\) and a treatment effect of \\(\\beta = 1.5\\).\n\ntrue_params &lt;- c(thres, beta)\nnames(true_params) &lt;- c(paste0(\"b_Intercept[\", 1:4, \"]\"), \"b_read\")\n\nposterior_draws &lt;- as.array(fit_full,\n                            variable = names(true_params))\n\nmcmc_recover_hist(posterior_draws, true = true_params) +\n  labs(title = \"Parameter Recovery\",\n       subtitle = \"Posterior distributions (histograms) vs. true values (vertical lines)\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\nThe histograms show the posterior distributions for each parameter, with vertical lines indicating the true values used in simulation. We can see that:\n\nThresholds: All four threshold parameters are well-recovered, with posterior distributions centered near the true values\nTreatment effect: The read coefficient is also well-recovered, with the posterior centered around 1.5"
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/index.html#conclusion",
    "href": "posts/posts/2026-01-09-ordinal-models/index.html#conclusion",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Conclusion",
    "text": "Conclusion\nThis short tutorial has demonstrated how cumulative link models provide a principled framework for ordinal regression.\nBy respecting the ordinal nature of the data, rather than treating categories as metric, cumulative link models yield more appropriate inferences for ordered categorical outcomes. The example above is intentionally simple; in cognitive science, data are typically clustered (e.g., by participants or items), which naturally calls for hierarchical models. For an application to ordinal ratings in this setting, see Taylor et al. (2022). For a more general introduction to hierarchical modeling with brms, see chapter 5 of Nicenboim, Schad, and Vasishth (2025)."
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/index.html#how-to-cite-this-post",
    "href": "posts/posts/2026-01-09-ordinal-models/index.html#how-to-cite-this-post",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "How to cite this post",
    "text": "How to cite this post\n\n\n\n\n\n\nTipCitation\n\n\n\n\n\nBibTeX:\n@misc{nicenboim2026bayesianordinalmodelsaveryshortpracticalguide,\n  author = {Nicenboim, Bruno},\n  title = {Bayesian ordinal models: A very short practical guide},\n  year = {2026},\n  month = {January},\n  url = {https://bruno.nicenboim.me/posts/posts/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/}\n}\nAPA:\nNicenboim, B. (2026, January 09). Bayesian ordinal models: A very short practical guide. https://bruno.nicenboim.me/posts/posts/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/"
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/index.html#session-info",
    "href": "posts/posts/2026-01-09-ordinal-models/index.html#session-info",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Session info",
    "text": "Session info\n\n\nR version 4.5.2 (2025-10-31)\nPlatform: x86_64-pc-linux-gnu\nRunning under: Ubuntu 24.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.12.0 \nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.12.0  LAPACK version 3.12.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Europe/Amsterdam\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ggridges_0.5.7      patchwork_1.3.2     bayesplot_1.15.0   \n[4] brms_2.23.0         Rcpp_1.1.1          ggplot2_4.0.1      \n[7] tidytable_0.11.2    extraDistr_1.10.0.1\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6            tensorA_0.36.2.1        xfun_0.55              \n [4] QuickJSR_1.8.1          htmlwidgets_1.6.4       processx_3.8.6         \n [7] inline_0.3.21           lattice_0.22-7          callr_3.7.6            \n[10] vctrs_0.6.5             tools_4.5.2             ps_1.9.1               \n[13] generics_0.1.4          stats4_4.5.2            parallel_4.5.2         \n[16] tibble_3.3.1            pkgconfig_2.0.3         Matrix_1.7-4           \n[19] data.table_1.18.0       checkmate_2.3.3         RColorBrewer_1.1-3     \n[22] S7_0.2.1                distributional_0.6.0    RcppParallel_5.1.11-1  \n[25] lifecycle_1.0.5         compiler_4.5.2          farver_2.1.2           \n[28] stringr_1.6.0           Brobdingnag_1.2-9       codetools_0.2-20       \n[31] htmltools_0.5.9         yaml_2.3.12             tidyr_1.3.2            \n[34] pillar_1.11.1           StanHeaders_2.36.0.9000 bridgesampling_1.2-1   \n[37] abind_1.4-8             nlme_3.1-168            posterior_1.6.1.9000   \n[40] rstan_2.36.0.9000       tidyselect_1.2.1        digest_0.6.39          \n[43] mvtnorm_1.3-3           stringi_1.8.7           purrr_1.2.1            \n[46] dplyr_1.1.4             reshape2_1.4.5          labeling_0.4.3         \n[49] fastmap_1.2.0           grid_4.5.2              cli_3.6.5              \n[52] magrittr_2.0.4          loo_2.9.0.9000          pkgbuild_1.4.8         \n[55] withr_3.0.2             scales_1.4.0            backports_1.5.0        \n[58] rmarkdown_2.30          matrixStats_1.5.0       otel_0.2.0             \n[61] gridExtra_2.3           coda_0.19-4.1           evaluate_1.0.5         \n[64] knitr_1.51              rstantools_2.6.0        rlang_1.1.7            \n[67] glue_1.8.0              jsonlite_2.0.0          R6_2.6.1               \n[70] plyr_1.8.9"
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/index.html#references",
    "href": "posts/posts/2026-01-09-ordinal-models/index.html#references",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "References",
    "text": "References\n\n\nBürkner, Paul-Christian, and Matti Vuorre. 2019. “Ordinal Regression Models in Psychology: A Tutorial.” Advances in Methods and Practices in Psychological Science 2 (1): 77–101. https://doi.org/10.1177/2515245918823199.\n\n\nNicenboim, Bruno, Daniel J. Schad, and Shravan Vasishth. 2025. Introduction to Bayesian Data Analysis for Cognitive Science. 1st ed. Chapman; Hall/CRC. https://doi.org/10.1201/9780429342646.\n\n\nTaylor, Jack E., Guillaume A. Rousselet, Christoph Scheepers, and Sara C. Sereno. 2022. “Rating Norms Should Be Calculated from Cumulative Link Mixed Effects Models.” Behavior Research Methods 55 (5): 2175–96. https://doi.org/10.3758/s13428-022-01814-7."
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/index.html#footnotes",
    "href": "posts/posts/2026-01-09-ordinal-models/index.html#footnotes",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe logistic distribution is not that different from the normal distribution: it is a symmetrical bell-shaped distribution. The reason for using this distribution rather than the normal distribution is that the modeling will need to rely on the cumulative density function (CDF), and the logistic tends to be more numerically stable↩︎\nShameless self-promotion of Nicenboim, Schad, and Vasishth (2025).↩︎"
  },
  {
    "objectID": "posts/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html",
    "href": "posts/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html",
    "title": "Posts",
    "section": "",
    "text": "Bayesian ordinal models: A very short practical guide\n\n\n\nStan\n\nBayesian\n\nTutorial\n\nR\n\nbrms\n\n\n\nUnderstanding and setting priors in Bayesian ordinal models with cumulative links\n\n\n\n\n\nJan 9, 2026\n\n\nBruno Nicenboim\n\n\n\n\n\n\n\n\n\n\n\n\nA simple way to model rankings with Stan\n\n\n\nStan\n\nBayesian\n\nR\n\nCitable\n\n\n\nHow to fit the exploded logit distribution in Stan to model ranking data\n\n\n\n\n\nJan 7, 2026\n\n\nBruno Nicenboim\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome to my new Quarto site\n\n\n\nMeta\n\nQuarto\n\n\n\n\n\n\n\n\n\nJan 6, 2026\n\n\nBruno Nicenboim\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "",
    "text": "I’ll first load some R packages that will be useful throughout this post.\nlibrary(extraDistr)\nlibrary(tidytable)\nlibrary(ggplot2)\nlibrary(brms)\nlibrary(bayesplot)\nlibrary(patchwork)\nlibrary(ggridges)\n\ntheme_set(theme_minimal(base_size = 14))"
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html#introduction",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html#introduction",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Introduction",
    "text": "Introduction\nThis post explains some nuances of Bayesian ordinal regression with cumulative links and focuses on how to set sensible priors. These models are appropriate for modeling data where the dependent variables are ordered responses without meaningful metric distances, such as Likert scales. The presentation builds on Bürkner and Vuorre (2019), but restricts attention to cumulative models."
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html#the-cumulative-link-framework",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html#the-cumulative-link-framework",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "The cumulative link framework",
    "text": "The cumulative link framework\nA cumulative link model assumes an underlying continuous latent variable (typically with a normal or logistic distribution) and a set of thresholds \\(\\tau_1, \\ldots, \\tau_K\\) that partition this scale. An observation falls in category \\(k\\) if the latent value, a random variable \\(\\tilde Y\\), lies between \\(\\tau_{k-1}\\) and \\(\\tau_k\\), with \\(\\tau_0 = -\\infty\\) and \\(\\tau_{K+1} = +\\infty\\).\n\nA concrete example\nConsider a 5-point Likert scale assessing understanding of Bayesian statistics with options: “nothing,” “a little,” “more or less,” “something,” and “everything.” This scale requires 4 thresholds. The probability for each category corresponds to the area between:\n\nCategory 1 (“nothing”): \\(-\\infty\\) to \\(\\tau_1\\)\nCategory 2 (“a little”): \\(\\tau_1\\) to \\(\\tau_2\\)\nCategory 3 (“more or less”): \\(\\tau_2\\) to \\(\\tau_3\\)\nCategory 4 (“something”): \\(\\tau_3\\) to \\(\\tau_4\\)\nCategory 5 (“everything”): \\(\\tau_4\\) to \\(+\\infty\\)\n\nLet’s visualize this with specific threshold values for a logistic distribution1. We make up the following thresholds\n\nthres &lt;- c(-2, -1, 1.5, 3)\n\n\n\nCode\ncategory &lt;- factor(1:5, labels = c(\"Nothing\", \"A little\", \"More or less\", \n                                     \"Something\", \"Everything\"))\n  \nx_vals &lt;- seq(-6, 6, length.out = 500)\nnorm_data &lt;- data.frame(\n  x = x_vals,\n  y = dlogis(x_vals)\n)\n\ncategory_positions &lt;- c(-Inf, thres, Inf)\ncategory_midpoints &lt;- (category_positions[-1] + category_positions[-length(category_positions)]) / 2\ncategory_midpoints[1] &lt;- max(-6, category_midpoints[1])\ncategory_midpoints[5] &lt;- min(6, category_midpoints[5])\n\nthreshold_labels &lt;- data.frame(\n  x = thres,\n  y = dlogis(thres) + 0.02,\n  label = paste0(\"τ[\", 1:4, \"]\")\n)\n\ncategory_labels &lt;- data.frame(\n  x = category_midpoints,\n  y = 0.02,\n  label = as.character(category)\n)\n\np1 &lt;- ggplot(norm_data, aes(x = x, y = y)) +\n  geom_line(linewidth = 1, color = \"steelblue\") +\n  geom_vline(xintercept = thres, linetype = \"dashed\", color = \"red\", linewidth = 0.8) +\n  geom_text(data = threshold_labels, aes(x = x, y = y, label = label),\n            parse = TRUE, size = 4.5, color = \"red\", hjust = -0.2, vjust = 0) +\n  geom_text(data = category_labels, aes(x = x, y = y, label = label),\n            size = 3.5, color = \"black\", hjust = 0.5) +\n  labs(title = \"Standard Logistic Distribution with Thresholds\",\n       x = \"Latent Variable\",\n       y = \"Density\") +\n  theme_minimal(base_size = 12)\n\nprint(p1)\n\n\n\n\n\n\n\n\n\n\n\nComputing category probabilities\nNow let’s calculate the probability mass between each threshold:\n\nprobs &lt;- diff(plogis(c(-Inf, thres, Inf)))\n\n# This above is just a more general case than:\n# probs &lt;- c(\n#   plogis(thres[1]),  # P(Y = 1)\n#   plogis(thres[2]) - plogis(thres[1]),  # P(Y = 2)\n#   plogis(thres[3]) - plogis(thres[2]),  # P(Y = 3)\n#   plogis(thres[4]) - plogis(thres[3]),  # P(Y = 4)\n#   1 - plogis(thres[4])  # P(Y = 5)\n# )\n\nprob_data &lt;- data.frame(\n  category = category,\n  probability = probs\n)\n\nprob_data\n\n      category probability\n1      Nothing  0.11920292\n2     A little  0.14973850\n3 More or less  0.54863305\n4    Something  0.13499965\n5   Everything  0.04742587\n\n\n\n\nCode\nggplot(prob_data, aes(x = category, y = probability, fill = category)) +\n  geom_col(alpha = 0.7, color = \"black\") +\n  scale_fill_brewer(palette = \"Blues\") +\n  labs(title = \"Category Probabilities (Baseline)\",\n       x = \"Understanding Level\",\n       y = \"Probability\") +\n  theme_minimal(base_size = 12) +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  ylim(0, 1)\n\n\n\n\n\n\n\n\n\nWe observe that the middle category (“more or less”) receive the highest probability mass.\n\n\nThe effect of shifting thresholds\nNow, let’s examine what happens when we shift all thresholds to the right by one unit and a half: simulating less understanding across the board.\n\nthres &lt;- thres + 1.5\n\n\n\n\n\n\n\n\n\n\n\n\n      category probability\n1      Nothing  0.37754067\n2     A little  0.24491866\n3 More or less  0.33011480\n4    Something  0.03643893\n5   Everything  0.01098694\n\n\n\n\n\n\n\n\n\nNotice how shifting the thresholds rightward decreases the probability of higher categories (more understanding) while increasing the probability of lower categories."
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html#modeling-an-intervention-effect",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html#modeling-an-intervention-effect",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Modeling an intervention effect",
    "text": "Modeling an intervention effect\nIn an ordinal regression with a cumulative link, our goal is to understand how a latent variable \\(\\tilde Y\\) shifts based on predictors or interventions. Suppose we want to assess how reading a book about Bayesian modeling2 affects responses to our understanding question.\n\nSimulating data\nLet’s generate synthetic data to illustrate this. We’ll simulate a group of students before and after reading our book.\nThis type of model assumes that, underlyingly, there is a continuous latent “rating”, and we specify a regression on this latent variable \\(\\tilde Y\\) that determines how the response categories are affected by our manipulation (note that there is no intercept here; the thresholds will later act as something close to intercepts for each category):\n\\[ \\tilde Y = \\eta + \\epsilon \\]\nwith\n\\[\\eta = \\beta \\cdot \\text{read}\\]\nwhere \\(\\text{read} \\in \\{0,1\\}\\) is a treatment indicator (in more realistic settings, one may prefer richer contrast coding; see Chapter 6 of Nicenboim, Schad, and Vasishth (2025)).\nIn principle, one could allow the predictor to have category-specific effects by estimating regressions for each threshold. However, Bürkner and Vuorre (2019) argue that while this parameterization is unproblematic for some ordinal models (such as sequential or adjacent-category models), it can lead to difficulties in model fitting for cumulative models.\nTo move from the continuous latent variable \\(\\tilde Y\\) to a discrete response, we define the observed outcome as follows:\n\\[Y = k \\quad \\text{if} \\quad \\tau_{k-1} &lt; \\tilde Y \\le \\tau_k\\] with boundary conditions \\(\\tau_0 = -\\infty\\) and \\(\\tau_{K+1} = +\\infty\\).\nWe keep the \\(k\\) thresholds (\\(\\tau_k\\)) defined above as the default cutoff points (brms refers to these as intercepts, though note the difference in sign convention below).\nGiven a cumulative link, the probability of observing category \\(k\\) is\n\\[\\Pr(Y = k \\mid \\text{read}) = F(\\tau_k - \\eta) - F(\\tau_{k-1} - \\eta)\\]\nHere, \\(F\\) denotes the cumulative distribution function of the error term \\(\\epsilon\\) of \\(\\tilde Y\\). We assume a logistic distribution for computational convenience, which yields a logistic cumulative link (assuming a normal distribution would lead to a probit link, with otherwise very similar expressions).\nThus, under a logistic cumulative link, the probability of observing category \\(k\\) is\n\\[\\Pr(Y = k \\mid \\text{read}) = \\operatorname{logit}^{-1}(\\tau_k - \\eta) - \\operatorname{logit}^{-1}(\\tau_{k-1} - \\eta)\\]\nwhere \\(\\operatorname{logit}^{-1}\\) denotes the CDF of the logistic distribution (available in R via plogis()). Notice that the regression term, \\(\\eta\\), is subtracted from each threshold.\nTo simulate data from this model, we treat the resulting category probabilities as defining a categorical distribution and sample responses accordingly:\n\\[Y \\sim \\text{Categorical}\\!\\left( \\Pr(Y=1), \\ldots, \\Pr(Y=K) \\right)\\]\nOne important insight is that \\(\\beta\\) affects all categories equally: when \\(\\beta &gt; 0\\), \\(\\tilde Y\\) increases, increasing the probability of higher response categories at the expense of lower response categories; when \\(\\beta &lt; 0\\), \\(\\tilde Y\\) decreases, increasing the probability of lower categories at the expense of higher response categories.\nIn the following simulation, we use the last thres values we defined (-0.5, 0.5, 3, 4.5) as the cutoff points of the model (\\(\\tau_k\\); called intercepts in brms), and we assume that reading increases \\(\\eta\\) (and also \\(\\tilde Y\\) on average) by \\(1.5\\). We generate data from 1000 participants before and after reading our book:\n\nset.seed(123)\n\nN &lt;- 1000\ntau &lt;- thres\nbeta &lt;- 1.5\neta_noread &lt;- 0 * beta\neta_read  &lt;- 1 * beta\n\ndf_sim &lt;- data.frame(\n  read = rep(c(0, 1), each = N),\n  category = c(\n    rcat(N, diff(plogis(c(-Inf, tau - eta_noread, Inf))), labels = category),\n    rcat(N, diff(plogis(c(-Inf, tau - eta_read, Inf))), labels = category)\n  )\n) |&gt;\n  mutate(response = as.numeric(category))\n\n# Display summary statistics\ntable(df_sim$read, df_sim$category)\n\n   \n    Nothing A little More or less Something Everything\n  0     382      238          329        40         11\n  1     114      154          549       138         45\n\n\nLet’s visualize the distribution of responses in both groups:\n\n\nCode\nggplot(df_sim, aes(x = response, fill = factor(read, labels = c(\"Before reading\", \"After reading\")), \n                   group = factor(read))) +\n  geom_bar(position = \"dodge\", alpha = 0.7, color = \"black\") +\n  scale_fill_manual(values = c(\"Before reading\" = \"coral\", \"After reading\" = \"forestgreen\")) +\n  labs(title = \"Distribution of Responses\",\n       x = \"Understanding Level\",\n       y = \"Count\",\n       fill = \"Group\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n\nNow that we have (simulated) data, let’s fit it with brms."
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html#understanding-priors-for-ordinal-models",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html#understanding-priors-for-ordinal-models",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Understanding priors for ordinal models",
    "text": "Understanding priors for ordinal models\nWhen fitting ordinal regression models with brms, we need to specify priors for (at least):\n\n“Intercepts” which in fact are thresholds or cutoff points\nRegression coefficients\n\nIn brms, the thresholds are automatically constrained to be ordered (\\(\\tau_1 &lt; \\tau_2 &lt; \\ldots &lt; \\tau_K\\)).\n\nWhy tight priors concentrate probability on extremes\nLet’s start by examining an intercept-only model with tight priors on the thresholds:\n\npriors_tight &lt;- c(\n  prior(normal(0, 0.5), class = \"Intercept\")\n)\n\nWith normal(0, 0.5) priors, all thresholds are pulled toward zero with relatively little spread. This concentrates the thresholds in a narrow region. This means that when thresholds cluster tightly around zero, most of the latent distribution’s mass falls outside the middle thresholds: either far below \\(\\tau_1\\) or far above \\(\\tau_K\\). This assigns most probability to extreme categories (the first and last).\n\nfit_prior_tight &lt;- brm(\n  response ~ 1,\n  data = df_sim,\n  family = cumulative(),\n  prior = priors_tight,\n  sample_prior = \"only\",\n  cores = 4,\n  seed = 123,\n  refresh = 0,\n  control = list(adapt_delta = 0.9) # avoid divergent transitions\n)\n\nWe define a visualization function ppd_lineplot() to inspect prior predictions.\n\n\nCode\nppd_lineplot &lt;- function(ypred, title = \"Prior Predictive Distribution\",\n                          subtitle = NULL) {\n  max_level &lt;- max(ypred) \n  proportions_per_draw &lt;- lapply(1:nrow(ypred), function(i) {\n    props &lt;- table(factor(ypred[i, ], levels = 1:max_level)) / ncol(ypred)\n    data.frame(\n      draw = i,\n      response = 1:max_level,\n      proportion = as.numeric(props)\n    )\n  })\n  ppd_data &lt;- do.call(rbind, proportions_per_draw)\n\n  # Add beeswarm-like jitter: horizontal offset based on density\n  ppd_data &lt;- ppd_data |&gt;\n    group_by(response) |&gt;\n    mutate(\n      prop_bin = round(proportion, 2)\n    ) |&gt;\n    group_by(response, prop_bin) |&gt;\n    mutate(\n      n_at_prop = n(),\n      rank_at_prop = row_number() - (n() + 1) / 2,\n      # Horizontal jitter proportional to local density\n      x_jitter = response + rank_at_prop * 0.3 / max(n_at_prop, 1)\n    ) |&gt;\n    ungroup()\n\n  ggplot(ppd_data, aes(x = x_jitter, y = proportion)) +\n    geom_line(aes(group = draw), alpha = 0.1, color = \"steelblue\") +\n    geom_point(alpha = 0.4, color = \"steelblue\", size = 1) +\n    geom_hline(yintercept = 0.2, linetype = \"dashed\", color = \"gray40\") +\n    scale_x_continuous(breaks = 1:5, labels = 1:5) +\n    scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +\n    labs(title = title,\n         subtitle = subtitle,\n         x = \"Response Category\",\n         y = \"Proportion\") +\n    theme_minimal(base_size = 12)\n}\n\n\n\nypred_prior_tight &lt;- posterior_predict(fit_prior_tight, ndraws = 200)\nppd_lineplot(ypred_prior_tight,\n              title = \"Prior Predictive Distribution: Tight Priors (SD = 0.5)\",\n              subtitle = \"Most probability mass concentrated in extreme categories\")\n\n\n\n\n\n\n\n\nWith tight priors, the model tends to predict extreme responses, as the thresholds cluster near zero and don’t span the full range of the latent distribution.\n\n\nIntercept-only model: Medium priors\nNow let’s use more dispersed priors:\n\npriors_medium &lt;- c(\n  prior(normal(0, 3), class = \"Intercept\")\n)\n\nWith normal(0, 3) priors, the thresholds can spread out more widely across the latent scale. This means the middle thresholds are more likely to be well-separated, capturing more of the distribution’s central mass and leading to more balanced predictions across all categories.\n\nfit_prior_medium &lt;- brm(\n  response ~ 1,\n  data = df_sim,\n  family = cumulative(),\n  prior = priors_medium,\n  sample_prior = \"only\",\n  cores = 4,\n  seed = 123,\n  refresh = 0\n)\n\n\nypred_prior_medium &lt;- posterior_predict(fit_prior_medium, ndraws = 200)\nppd_lineplot(ypred_prior_medium,\n              title = \"Prior Predictive Distribution: Medium Priors (SD = 3)\",\n              subtitle = \"More balanced distribution across categories\")\n\n\n\n\n\n\n\n\n\n\nIntercept-only model: Diffuse priors\nLet’s examine very diffuse priors:\n\npriors_diffuse &lt;- c(\n  prior(normal(0, 10), class = \"Intercept\")\n)\n\nfit_prior_diffuse &lt;- brm(\n  response ~ 1,\n  data = df_sim,\n  family = cumulative(),\n  prior = priors_diffuse,\n  sample_prior = \"only\",\n  cores = 4,\n  seed = 123,\n  refresh = 0,\n  control = list(adapt_delta = 0.9)\n)\n\n\nypred_prior_diffuse &lt;- posterior_predict(fit_prior_diffuse, ndraws = 200)\nppd_lineplot(ypred_prior_diffuse, \n              title = \"Prior Predictive Distribution: Diffuse Priors (SD = 10)\",\n       subtitle = \"Very flat distribution - least informative\")\n\n\n\n\n\n\n\n\nVery diffuse priors allow thresholds to be extremely spread out, often resulting in a very sparse distribution across categories.\n\n\nIntercept-only model: Nudging priors\nWe might have substantive information suggesting most people start as beginners. We can encode this by centering the threshold prior at a positive value:\n\npriors_mid_inf &lt;- c(\n  prior(normal(1, 3), class = \"Intercept\")\n)\n\nfit_mid_inf &lt;- brm( \n  response ~ 1,\n  data = df_sim,\n  family = cumulative(),\n  prior = priors_mid_inf,\n  sample_prior = \"only\",\n  cores = 4,\n  seed = 123,\n  refresh = 0\n)\n\n\nypred_mid_inf &lt;- posterior_predict(fit_mid_inf, ndraws = 200)\nppd_lineplot(ypred_mid_inf, \n              title = \"Prior Predictive Distribution: Nudged Priors (Mean = 1, SD = 3)\",\n       subtitle = \"Prior belief that lower understanding is more common\")\n\n\n\n\n\n\n\n\nBy centering the threshold prior at 1 instead of 0, we shift thresholds rightward, making lower categories more probable a priori.\n\n\nPrior predictive distribution for the slope\nLet’s also examine what our prior beliefs about the treatment effect imply:\n\npriors_full &lt;- c(\n  prior(normal(0, 3), class = \"Intercept\"),\n  prior(normal(0, 1.5), class = \"b\")\n)\n\nfit_slope_prior &lt;- brm(\n  response ~ read,\n  data = df_sim,\n  family = cumulative(),\n  prior = priors_full,\n  sample_prior = \"only\",\n  cores = 4,\n  seed = 123,\n  refresh = 0,\n  control = list(adapt_delta = 0.9)\n)\n\n\nypred_slope_prior &lt;- posterior_predict(fit_slope_prior, ndraws = 200)\nypred_noread &lt;- ypred_slope_prior[, 1:1000]\nypred_read &lt;- ypred_slope_prior[, 1001:2000]\nypred_diff &lt;- abs(ypred_noread - ypred_read)\nppd_lineplot(ypred_diff,\n              title = \"Prior Predictive Distribution: Full Model with Slope Prior\",\n       subtitle = \"normal(0, 1.5) prior on treatment effect\")\n\n\n\n\n\n\n\n\nThe prior normal(0, 1.5) on the slope is weakly informative: it allows for moderate effects in either direction while gently regularizing against implausibly large effects.\n\n\nFitting to the simulated data\nNow let’s fit the model to our simulated data:\n\nfit_full &lt;- brm(\n  response ~ read,\n  data = df_sim,\n  family = cumulative(),\n  prior = priors_full,\n  cores = 4,\n  seed = 123,\n  warmup = 1000,\n  iter = 2000,\n  refresh = 0\n)\n\n\nfit_full\n\n Family: cumulative \n  Links: mu = logit \nFormula: response ~ read \n   Data: df_sim (Number of observations: 2000) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]    -0.50      0.06    -0.62    -0.38 1.00     4501     3153\nIntercept[2]     0.50      0.06     0.37     0.62 1.00     4802     3359\nIntercept[3]     2.98      0.09     2.79     3.16 1.00     3939     3068\nIntercept[4]     4.55      0.15     4.26     4.85 1.00     3991     2905\nread             1.50      0.09     1.32     1.66 1.00     3854     2924\n\nFurther Distributional Parameters:\n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nIf this were real data, based on the read coefficient, we would conclude that reading our book affects understanding. The positive coefficient read ≈ 1.5 indicates that reading makes higher categories (more understanding) more probable.\n\n\nInterpreting predicted probabilities\nTo understand what the model estimates mean in practical terms, let’s examine the predicted probabilities:\n\n\nCode\nce &lt;- conditional_effects(fit_full, effects = \"read\", categorical = TRUE)\n\nplot(ce, plot = FALSE)[[1]] +\n  scale_fill_brewer(palette = \"RdYlGn\", direction = 1) +\n  labs(title = \"Predicted Response Probabilities by Reading Status\",\n       subtitle = \"Model predictions with 95% credible intervals\",\n       x = \"Read Book\",\n       y = \"Predicted Probability\",\n       fill = \"response\") +\n  theme_minimal(base_size = 12) +\n  theme(legend.position = \"right\")\n\n\n\n\n\n\n\n\n\nThe conditional effects plot shows how reading the book shifts the entire distribution toward higher understanding categories. Before reading (read = 0), lower categories have higher probabilities; after reading (read = 1), the distribution shifts substantially toward “something” and “everything.”\nWe can also examine specific fitted values:\n\n\nCode\nnew_data &lt;- data.frame(read = c(0, 1))\nfitted_probs &lt;- fitted(fit_full, newdata = new_data)\n\nfitted_df &lt;- data.frame(\n  read = rep(c(\"Before\", \"After\"), each = 5),\n  category = rep(1:5, times = 2),\n  probability = c(fitted_probs[1, \"Estimate\", ], fitted_probs[2, \"Estimate\",]),\n  lower = c(fitted_probs[1, \"Q2.5\",], fitted_probs[2 , \"Q2.5\",]),\n  upper = c(fitted_probs[1, \"Q97.5\",], fitted_probs[2 , \"Q97.5\",])\n)\n\nggplot(fitted_df, aes(x = factor(category), y = probability, fill = read)) +\n  geom_col(position = \"dodge\", alpha = 0.7, color = \"black\") +\n  geom_errorbar(aes(ymin = lower, ymax = upper), \n                position = position_dodge(0.9), width = 0.2) +\n  scale_fill_manual(values = c(\"Before\" = \"coral\", \"After\" = \"forestgreen\")) +\n  labs(title = \"Model-Predicted Probabilities with 95% Credible Intervals\",\n       x = \"Understanding Category\",\n       y = \"Predicted Probability\",\n       fill = \"Reading Status\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n\nThe fitted probabilities show concrete estimates: for instance, before reading, the probability of responding “nothing” is about 0.38, whereas after reading it drops to about 0.12. Conversely, the probability of responding “everything” increases from about 0.01 to 0.05.\n\n\nPosterior predictive check\nFinally, let’s verify that the model fits the observed data well:\n\npp_check(fit_full, type = \"bars\", ndraws = 100) +\n  labs(title = \"Posterior Predictive Check: Full Model\",\n       subtitle = \"Model predictions compared to observed data\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\nThe posterior predictive distribution closely matches the observed data patterns, indicating good model fit."
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html#recovery-of-the-parameters",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html#recovery-of-the-parameters",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Recovery of the parameters",
    "text": "Recovery of the parameters\nLet’s examine whether the model successfully recovered the true parameters we used to generate the data. We simulated with thresholds \\(\\tau = [-0.5, 0.5, 3, 4.5]\\) and a treatment effect of \\(\\beta = 1.5\\).\n\ntrue_params &lt;- c(thres, beta)\nnames(true_params) &lt;- c(paste0(\"b_Intercept[\", 1:4, \"]\"), \"b_read\")\n\nposterior_draws &lt;- as.array(fit_full,\n                            variable = names(true_params))\n\nmcmc_recover_hist(posterior_draws, true = true_params) +\n  labs(title = \"Parameter Recovery\",\n       subtitle = \"Posterior distributions (histograms) vs. true values (vertical lines)\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\nThe histograms show the posterior distributions for each parameter, with vertical lines indicating the true values used in simulation. We can see that:\n\nThresholds: All four threshold parameters are well-recovered, with posterior distributions centered near the true values\nTreatment effect: The read coefficient is also well-recovered, with the posterior centered around 1.5"
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html#conclusion",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html#conclusion",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Conclusion",
    "text": "Conclusion\nThis short tutorial has demonstrated how cumulative link models provide a principled framework for ordinal regression.\nBy respecting the ordinal nature of the data, rather than treating categories as metric, cumulative link models yield more appropriate inferences for ordered categorical outcomes. The example above is intentionally simple; in cognitive science, data are typically clustered (e.g., by participants or items), which naturally calls for hierarchical models. For an application to ordinal ratings in this setting, see Taylor et al. (2022). For a more general introduction to hierarchical modeling with brms, see chapter 5 of Nicenboim, Schad, and Vasishth (2025)."
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html#how-to-cite-this-post",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html#how-to-cite-this-post",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "How to cite this post",
    "text": "How to cite this post\n\n\n\n\n\n\nTipCitation\n\n\n\n\n\nBibTeX:\n@misc{nicenboim2026bayesianordinalmodelsaveryshortpracticalguide,\n  author = {Nicenboim, Bruno},\n  title = {Bayesian ordinal models: A very short practical guide},\n  year = {2026},\n  month = {January},\n  url = {https://bruno.nicenboim.me/posts/posts/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/}\n}\nAPA:\nNicenboim, B. (2026, January 09). Bayesian ordinal models: A very short practical guide. https://bruno.nicenboim.me/posts/posts/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/"
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html#session-info",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html#session-info",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Session info",
    "text": "Session info\n\n\nR version 4.5.2 (2025-10-31)\nPlatform: x86_64-pc-linux-gnu\nRunning under: Ubuntu 24.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.12.0 \nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.12.0  LAPACK version 3.12.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Europe/Amsterdam\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ggridges_0.5.7      patchwork_1.3.2     bayesplot_1.15.0   \n[4] brms_2.23.0         Rcpp_1.1.1          ggplot2_4.0.1      \n[7] tidytable_0.11.2    extraDistr_1.10.0.1\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6            tensorA_0.36.2.1        xfun_0.55              \n [4] QuickJSR_1.8.1          htmlwidgets_1.6.4       processx_3.8.6         \n [7] inline_0.3.21           lattice_0.22-7          callr_3.7.6            \n[10] vctrs_0.6.5             tools_4.5.2             ps_1.9.1               \n[13] generics_0.1.4          stats4_4.5.2            parallel_4.5.2         \n[16] tibble_3.3.1            pkgconfig_2.0.3         Matrix_1.7-4           \n[19] data.table_1.18.0       checkmate_2.3.3         RColorBrewer_1.1-3     \n[22] S7_0.2.1                distributional_0.6.0    RcppParallel_5.1.11-1  \n[25] lifecycle_1.0.5         compiler_4.5.2          farver_2.1.2           \n[28] stringr_1.6.0           Brobdingnag_1.2-9       codetools_0.2-20       \n[31] htmltools_0.5.9         yaml_2.3.12             tidyr_1.3.2            \n[34] pillar_1.11.1           StanHeaders_2.36.0.9000 bridgesampling_1.2-1   \n[37] abind_1.4-8             nlme_3.1-168            posterior_1.6.1.9000   \n[40] rstan_2.36.0.9000       tidyselect_1.2.1        digest_0.6.39          \n[43] mvtnorm_1.3-3           stringi_1.8.7           purrr_1.2.1            \n[46] dplyr_1.1.4             reshape2_1.4.5          labeling_0.4.3         \n[49] fastmap_1.2.0           grid_4.5.2              cli_3.6.5              \n[52] magrittr_2.0.4          loo_2.9.0.9000          pkgbuild_1.4.8         \n[55] withr_3.0.2             scales_1.4.0            backports_1.5.0        \n[58] rmarkdown_2.30          matrixStats_1.5.0       otel_0.2.0             \n[61] gridExtra_2.3           coda_0.19-4.1           evaluate_1.0.5         \n[64] knitr_1.51              rstantools_2.6.0        rlang_1.1.7            \n[67] glue_1.8.0              jsonlite_2.0.0          R6_2.6.1               \n[70] plyr_1.8.9"
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html#references",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html#references",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "References",
    "text": "References\n\n\nBürkner, Paul-Christian, and Matti Vuorre. 2019. “Ordinal Regression Models in Psychology: A Tutorial.” Advances in Methods and Practices in Psychological Science 2 (1): 77–101. https://doi.org/10.1177/2515245918823199.\n\n\nNicenboim, Bruno, Daniel J. Schad, and Shravan Vasishth. 2025. Introduction to Bayesian Data Analysis for Cognitive Science. 1st ed. Chapman; Hall/CRC. https://doi.org/10.1201/9780429342646.\n\n\nTaylor, Jack E., Guillaume A. Rousselet, Christoph Scheepers, and Sara C. Sereno. 2022. “Rating Norms Should Be Calculated from Cumulative Link Mixed Effects Models.” Behavior Research Methods 55 (5): 2175–96. https://doi.org/10.3758/s13428-022-01814-7."
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html#footnotes",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide.html#footnotes",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe logistic distribution is not that different from the normal distribution: it is a symmetrical bell-shaped distribution. The reason for using this distribution rather than the normal distribution is that the modeling will need to rely on the cumulative density function (CDF), and the logistic tends to be more numerically stable↩︎\nShameless self-promotion of Nicenboim, Schad, and Vasishth (2025).↩︎"
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "",
    "text": "I’ll first load some R packages that will be useful throughout this post.\nlibrary(extraDistr)\nlibrary(tidytable)\nlibrary(ggplot2)\nlibrary(brms)\nlibrary(bayesplot)\nlibrary(patchwork)\nlibrary(ggridges)\n\ntheme_set(theme_minimal(base_size = 14))"
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html#introduction",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html#introduction",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Introduction",
    "text": "Introduction\nThis post explains some nuances of Bayesian ordinal regression with cumulative links and focuses on how to set sensible priors. These models are appropriate for modeling data where the dependent variables are ordered responses without meaningful metric distances, such as Likert scales. The presentation builds on Bürkner and Vuorre (2019), but restricts attention to cumulative models."
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html#the-cumulative-link-framework",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html#the-cumulative-link-framework",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "The cumulative link framework",
    "text": "The cumulative link framework\nA cumulative link model assumes an underlying continuous latent variable (typically with a normal or logistic distribution) and a set of thresholds \\(\\tau_1, \\ldots, \\tau_K\\) that partition this scale. An observation falls in category \\(k\\) if the latent value, a random variable \\(\\tilde Y\\), lies between \\(\\tau_{k-1}\\) and \\(\\tau_k\\), with \\(\\tau_0 = -\\infty\\) and \\(\\tau_{K+1} = +\\infty\\).\n\nA concrete example\nConsider a 5-point Likert scale assessing understanding of Bayesian statistics with options: “nothing,” “a little,” “more or less,” “something,” and “everything.” This scale requires 4 thresholds. The probability for each category corresponds to the area between:\n\nCategory 1 (“nothing”): \\(-\\infty\\) to \\(\\tau_1\\)\nCategory 2 (“a little”): \\(\\tau_1\\) to \\(\\tau_2\\)\nCategory 3 (“more or less”): \\(\\tau_2\\) to \\(\\tau_3\\)\nCategory 4 (“something”): \\(\\tau_3\\) to \\(\\tau_4\\)\nCategory 5 (“everything”): \\(\\tau_4\\) to \\(+\\infty\\)\n\nLet’s visualize this with specific threshold values for a logistic distribution1. We make up the following thresholds\n\nthres &lt;- c(-2, -1, 1.5, 3)\n\n\n\nCode\ncategory &lt;- factor(1:5, labels = c(\"Nothing\", \"A little\", \"More or less\", \n                                     \"Something\", \"Everything\"))\n  \nx_vals &lt;- seq(-6, 6, length.out = 500)\nnorm_data &lt;- data.frame(\n  x = x_vals,\n  y = dlogis(x_vals)\n)\n\ncategory_positions &lt;- c(-Inf, thres, Inf)\ncategory_midpoints &lt;- (category_positions[-1] + category_positions[-length(category_positions)]) / 2\ncategory_midpoints[1] &lt;- max(-6, category_midpoints[1])\ncategory_midpoints[5] &lt;- min(6, category_midpoints[5])\n\nthreshold_labels &lt;- data.frame(\n  x = thres,\n  y = dlogis(thres) + 0.02,\n  label = paste0(\"τ[\", 1:4, \"]\")\n)\n\ncategory_labels &lt;- data.frame(\n  x = category_midpoints,\n  y = 0.02,\n  label = as.character(category)\n)\n\np1 &lt;- ggplot(norm_data, aes(x = x, y = y)) +\n  geom_line(linewidth = 1, color = \"steelblue\") +\n  geom_vline(xintercept = thres, linetype = \"dashed\", color = \"red\", linewidth = 0.8) +\n  geom_text(data = threshold_labels, aes(x = x, y = y, label = label),\n            parse = TRUE, size = 4.5, color = \"red\", hjust = -0.2, vjust = 0) +\n  geom_text(data = category_labels, aes(x = x, y = y, label = label),\n            size = 3.5, color = \"black\", hjust = 0.5) +\n  labs(title = \"Standard Logistic Distribution with Thresholds\",\n       x = \"Latent Variable\",\n       y = \"Density\") +\n  theme_minimal(base_size = 12)\n\nprint(p1)\n\n\n\n\n\n\n\n\n\n\n\nComputing category probabilities\nNow let’s calculate the probability mass between each threshold:\n\nprobs &lt;- diff(plogis(c(-Inf, thres, Inf)))\n\n# This above is just a more general case than:\n# probs &lt;- c(\n#   plogis(thres[1]),  # P(Y = 1)\n#   plogis(thres[2]) - plogis(thres[1]),  # P(Y = 2)\n#   plogis(thres[3]) - plogis(thres[2]),  # P(Y = 3)\n#   plogis(thres[4]) - plogis(thres[3]),  # P(Y = 4)\n#   1 - plogis(thres[4])  # P(Y = 5)\n# )\n\nprob_data &lt;- data.frame(\n  category = category,\n  probability = probs\n)\n\nprob_data\n\n      category probability\n1      Nothing  0.11920292\n2     A little  0.14973850\n3 More or less  0.54863305\n4    Something  0.13499965\n5   Everything  0.04742587\n\n\n\n\nCode\nggplot(prob_data, aes(x = category, y = probability, fill = category)) +\n  geom_col(alpha = 0.7, color = \"black\") +\n  scale_fill_brewer(palette = \"Blues\") +\n  labs(title = \"Category Probabilities (Baseline)\",\n       x = \"Understanding Level\",\n       y = \"Probability\") +\n  theme_minimal(base_size = 12) +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  ylim(0, 1)\n\n\n\n\n\n\n\n\n\nWe observe that the middle category (“more or less”) receive the highest probability mass.\n\n\nThe effect of shifting thresholds\nNow, let’s examine what happens when we shift all thresholds to the right by one unit and a half: simulating less understanding across the board.\n\nthres &lt;- thres + 1.5\n\n\n\n\n\n\n\n\n\n\n\n\n      category probability\n1      Nothing  0.37754067\n2     A little  0.24491866\n3 More or less  0.33011480\n4    Something  0.03643893\n5   Everything  0.01098694\n\n\n\n\n\n\n\n\n\nNotice how shifting the thresholds rightward decreases the probability of higher categories (more understanding) while increasing the probability of lower categories."
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html#modeling-an-intervention-effect",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html#modeling-an-intervention-effect",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Modeling an intervention effect",
    "text": "Modeling an intervention effect\nIn an ordinal regression with a cumulative link, our goal is to understand how a latent variable \\(\\tilde Y\\) shifts based on predictors or interventions. Suppose we want to assess how reading a book about Bayesian modeling2 affects responses to our understanding question.\n\nSimulating data\nLet’s generate synthetic data to illustrate this. We’ll simulate a group of students before and after reading our book.\nThis type of model assumes that, underlyingly, there is a continuous latent “rating”, and we specify a regression on this latent variable \\(\\tilde Y\\) that determines how the response categories are affected by our manipulation (note that there is no intercept here; the thresholds will later act as something close to intercepts for each category):\n\\[ \\tilde Y = \\eta + \\epsilon \\]\nwith\n\\[\\eta = \\beta \\cdot \\text{read}\\]\nwhere \\(\\text{read} \\in \\{0,1\\}\\) is a treatment indicator (in more realistic settings, one may prefer richer contrast coding; see Chapter 6 of Nicenboim, Schad, and Vasishth (2025)).\nIn principle, one could allow the predictor to have category-specific effects by estimating regressions for each threshold. However, Bürkner and Vuorre (2019) argue that while this parameterization is unproblematic for some ordinal models (such as sequential or adjacent-category models), it can lead to difficulties in model fitting for cumulative models.\nTo move from the continuous latent variable \\(\\tilde Y\\) to a discrete response, we define the observed outcome as follows:\n\\[Y = k \\quad \\text{if} \\quad \\tau_{k-1} &lt; \\tilde Y \\le \\tau_k\\] with boundary conditions \\(\\tau_0 = -\\infty\\) and \\(\\tau_{K+1} = +\\infty\\).\nWe keep the \\(k\\) thresholds (\\(\\tau_k\\)) defined above as the default cutoff points (brms refers to these as intercepts, though note the difference in sign convention below).\nGiven a cumulative link, the probability of observing category \\(k\\) is\n\\[\\Pr(Y = k \\mid \\text{read}) = F(\\tau_k - \\eta) - F(\\tau_{k-1} - \\eta)\\]\nHere, \\(F\\) denotes the cumulative distribution function of the error term \\(\\epsilon\\) of \\(\\tilde Y\\). We assume a logistic distribution for computational convenience, which yields a logistic cumulative link (assuming a normal distribution would lead to a probit link, with otherwise very similar expressions).\nThus, under a logistic cumulative link, the probability of observing category \\(k\\) is\n\\[\\Pr(Y = k \\mid \\text{read}) = \\operatorname{logit}^{-1}(\\tau_k - \\eta) - \\operatorname{logit}^{-1}(\\tau_{k-1} - \\eta)\\]\nwhere \\(\\operatorname{logit}^{-1}\\) denotes the CDF of the logistic distribution (available in R via plogis()). Notice that the regression term, \\(\\eta\\), is subtracted from each threshold.\nTo simulate data from this model, we treat the resulting category probabilities as defining a categorical distribution and sample responses accordingly:\n\\[Y \\sim \\text{Categorical}\\!\\left( \\Pr(Y=1), \\ldots, \\Pr(Y=K) \\right)\\]\nOne important insight is that \\(\\beta\\) affects all categories equally: when \\(\\beta &gt; 0\\), \\(\\tilde Y\\) increases, increasing the probability of higher response categories at the expense of lower response categories; when \\(\\beta &lt; 0\\), \\(\\tilde Y\\) decreases, increasing the probability of lower categories at the expense of higher response categories.\nIn the following simulation, we use the last thres values we defined (-0.5, 0.5, 3, 4.5) as the cutoff points of the model (\\(\\tau_k\\); called intercepts in brms), and we assume that reading increases \\(\\eta\\) (and also \\(\\tilde Y\\) on average) by \\(1.5\\). We generate data from 1000 participants before and after reading our book:\n\nset.seed(123)\n\nN &lt;- 1000\ntau &lt;- thres\nbeta &lt;- 1.5\neta_noread &lt;- 0 * beta\neta_read  &lt;- 1 * beta\n\ndf_sim &lt;- data.frame(\n  read = rep(c(0, 1), each = N),\n  category = c(\n    rcat(N, diff(plogis(c(-Inf, tau - eta_noread, Inf))), labels = category),\n    rcat(N, diff(plogis(c(-Inf, tau - eta_read, Inf))), labels = category)\n  )\n) |&gt;\n  mutate(response = as.numeric(category))\n\n# Display summary statistics\ntable(df_sim$read, df_sim$category)\n\n   \n    Nothing A little More or less Something Everything\n  0     382      238          329        40         11\n  1     114      154          549       138         45\n\n\nLet’s visualize the distribution of responses in both groups:\n\n\nCode\nggplot(df_sim, aes(x = response, fill = factor(read, labels = c(\"Before reading\", \"After reading\")), \n                   group = factor(read))) +\n  geom_bar(position = \"dodge\", alpha = 0.7, color = \"black\") +\n  scale_fill_manual(values = c(\"Before reading\" = \"coral\", \"After reading\" = \"forestgreen\")) +\n  labs(title = \"Distribution of Responses\",\n       x = \"Understanding Level\",\n       y = \"Count\",\n       fill = \"Group\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n\nNow that we have (simulated) data, let’s fit it with brms."
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html#understanding-priors-for-ordinal-models",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html#understanding-priors-for-ordinal-models",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Understanding priors for ordinal models",
    "text": "Understanding priors for ordinal models\nWhen fitting ordinal regression models with brms, we need to specify priors for (at least):\n\n“Intercepts” which in fact are thresholds or cutoff points\nRegression coefficients\n\nIn brms, the thresholds are automatically constrained to be ordered (\\(\\tau_1 &lt; \\tau_2 &lt; \\ldots &lt; \\tau_K\\)).\n\nWhy tight priors concentrate probability on extremes\nLet’s start by examining an intercept-only model with tight priors on the thresholds:\n\npriors_tight &lt;- c(\n  prior(normal(0, 0.5), class = \"Intercept\")\n)\n\nWith normal(0, 0.5) priors, all thresholds are pulled toward zero with relatively little spread. This concentrates the thresholds in a narrow region. This means that when thresholds cluster tightly around zero, most of the latent distribution’s mass falls outside the middle thresholds: either far below \\(\\tau_1\\) or far above \\(\\tau_K\\). This assigns most probability to extreme categories (the first and last).\n\nfit_prior_tight &lt;- brm(\n  response ~ 1,\n  data = df_sim,\n  family = cumulative(),\n  prior = priors_tight,\n  sample_prior = \"only\",\n  cores = 4,\n  seed = 123,\n  refresh = 0,\n  control = list(adapt_delta = 0.9) # avoid divergent transitions\n)\n\nWe define a visualization function ppd_lineplot() to inspect prior predictions.\n\n\nCode\nppd_lineplot &lt;- function(ypred, title = \"Prior Predictive Distribution\",\n                          subtitle = NULL) {\n  max_level &lt;- max(ypred) \n  proportions_per_draw &lt;- lapply(1:nrow(ypred), function(i) {\n    props &lt;- table(factor(ypred[i, ], levels = 1:max_level)) / ncol(ypred)\n    data.frame(\n      draw = i,\n      response = 1:max_level,\n      proportion = as.numeric(props)\n    )\n  })\n  ppd_data &lt;- do.call(rbind, proportions_per_draw)\n\n  # Add beeswarm-like jitter: horizontal offset based on density\n  ppd_data &lt;- ppd_data |&gt;\n    group_by(response) |&gt;\n    mutate(\n      prop_bin = round(proportion, 2)\n    ) |&gt;\n    group_by(response, prop_bin) |&gt;\n    mutate(\n      n_at_prop = n(),\n      rank_at_prop = row_number() - (n() + 1) / 2,\n      # Horizontal jitter proportional to local density\n      x_jitter = response + rank_at_prop * 0.3 / max(n_at_prop, 1)\n    ) |&gt;\n    ungroup()\n\n  ggplot(ppd_data, aes(x = x_jitter, y = proportion)) +\n    geom_line(aes(group = draw), alpha = 0.1, color = \"steelblue\") +\n    geom_point(alpha = 0.4, color = \"steelblue\", size = 1) +\n    geom_hline(yintercept = 0.2, linetype = \"dashed\", color = \"gray40\") +\n    scale_x_continuous(breaks = 1:5, labels = 1:5) +\n    scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +\n    labs(title = title,\n         subtitle = subtitle,\n         x = \"Response Category\",\n         y = \"Proportion\") +\n    theme_minimal(base_size = 12)\n}\n\n\n\nypred_prior_tight &lt;- posterior_predict(fit_prior_tight, ndraws = 200)\nppd_lineplot(ypred_prior_tight,\n              title = \"Prior Predictive Distribution: Tight Priors (SD = 0.5)\",\n              subtitle = \"Most probability mass concentrated in extreme categories\")\n\n\n\n\n\n\n\n\nWith tight priors, the model tends to predict extreme responses, as the thresholds cluster near zero and don’t span the full range of the latent distribution.\n\n\nIntercept-only model: Medium priors\nNow let’s use more dispersed priors:\n\npriors_medium &lt;- c(\n  prior(normal(0, 3), class = \"Intercept\")\n)\n\nWith normal(0, 3) priors, the thresholds can spread out more widely across the latent scale. This means the middle thresholds are more likely to be well-separated, capturing more of the distribution’s central mass and leading to more balanced predictions across all categories.\n\nfit_prior_medium &lt;- brm(\n  response ~ 1,\n  data = df_sim,\n  family = cumulative(),\n  prior = priors_medium,\n  sample_prior = \"only\",\n  cores = 4,\n  seed = 123,\n  refresh = 0\n)\n\n\nypred_prior_medium &lt;- posterior_predict(fit_prior_medium, ndraws = 200)\nppd_lineplot(ypred_prior_medium,\n              title = \"Prior Predictive Distribution: Medium Priors (SD = 3)\",\n              subtitle = \"More balanced distribution across categories\")\n\n\n\n\n\n\n\n\n\n\nIntercept-only model: Diffuse priors\nLet’s examine very diffuse priors:\n\npriors_diffuse &lt;- c(\n  prior(normal(0, 10), class = \"Intercept\")\n)\n\nfit_prior_diffuse &lt;- brm(\n  response ~ 1,\n  data = df_sim,\n  family = cumulative(),\n  prior = priors_diffuse,\n  sample_prior = \"only\",\n  cores = 4,\n  seed = 123,\n  refresh = 0,\n  control = list(adapt_delta = 0.9)\n)\n\n\nypred_prior_diffuse &lt;- posterior_predict(fit_prior_diffuse, ndraws = 200)\nppd_lineplot(ypred_prior_diffuse, \n              title = \"Prior Predictive Distribution: Diffuse Priors (SD = 10)\",\n       subtitle = \"Very flat distribution - least informative\")\n\n\n\n\n\n\n\n\nVery diffuse priors allow thresholds to be extremely spread out, often resulting in a very sparse distribution across categories.\n\n\nIntercept-only model: Nudging priors\nWe might have substantive information suggesting most people start as beginners. We can encode this by centering the threshold prior at a positive value:\n\npriors_mid_inf &lt;- c(\n  prior(normal(1, 3), class = \"Intercept\")\n)\n\nfit_mid_inf &lt;- brm( \n  response ~ 1,\n  data = df_sim,\n  family = cumulative(),\n  prior = priors_mid_inf,\n  sample_prior = \"only\",\n  cores = 4,\n  seed = 123,\n  refresh = 0\n)\n\n\nypred_mid_inf &lt;- posterior_predict(fit_mid_inf, ndraws = 200)\nppd_lineplot(ypred_mid_inf, \n              title = \"Prior Predictive Distribution: Nudged Priors (Mean = 1, SD = 3)\",\n       subtitle = \"Prior belief that lower understanding is more common\")\n\n\n\n\n\n\n\n\nBy centering the threshold prior at 1 instead of 0, we shift thresholds rightward, making lower categories more probable a priori.\n\n\nPrior predictive distribution for the slope\nLet’s also examine what our prior beliefs about the treatment effect imply:\n\npriors_full &lt;- c(\n  prior(normal(0, 3), class = \"Intercept\"),\n  prior(normal(0, 1.5), class = \"b\")\n)\n\nfit_slope_prior &lt;- brm(\n  response ~ read,\n  data = df_sim,\n  family = cumulative(),\n  prior = priors_full,\n  sample_prior = \"only\",\n  cores = 4,\n  seed = 123,\n  refresh = 0,\n  control = list(adapt_delta = 0.9)\n)\n\n\nypred_slope_prior &lt;- posterior_predict(fit_slope_prior, ndraws = 200)\nypred_noread &lt;- ypred_slope_prior[, 1:1000]\nypred_read &lt;- ypred_slope_prior[, 1001:2000]\nypred_diff &lt;- abs(ypred_noread - ypred_read)\nppd_lineplot(ypred_diff,\n              title = \"Prior Predictive Distribution: Full Model with Slope Prior\",\n       subtitle = \"normal(0, 1.5) prior on treatment effect\")\n\n\n\n\n\n\n\n\nThe prior normal(0, 1.5) on the slope is weakly informative: it allows for moderate effects in either direction while gently regularizing against implausibly large effects.\n\n\nFitting to the simulated data\nNow let’s fit the model to our simulated data:\n\nfit_full &lt;- brm(\n  response ~ read,\n  data = df_sim,\n  family = cumulative(),\n  prior = priors_full,\n  cores = 4,\n  seed = 123,\n  warmup = 1000,\n  iter = 2000,\n  refresh = 0\n)\n\n\nfit_full\n\n Family: cumulative \n  Links: mu = logit \nFormula: response ~ read \n   Data: df_sim (Number of observations: 2000) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]    -0.50      0.06    -0.62    -0.38 1.00     4501     3153\nIntercept[2]     0.50      0.06     0.37     0.62 1.00     4802     3359\nIntercept[3]     2.98      0.09     2.79     3.16 1.00     3939     3068\nIntercept[4]     4.55      0.15     4.26     4.85 1.00     3991     2905\nread             1.50      0.09     1.32     1.66 1.00     3854     2924\n\nFurther Distributional Parameters:\n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nIf this were real data, based on the read coefficient, we would conclude that reading our book affects understanding. The positive coefficient read ≈ 1.5 indicates that reading makes higher categories (more understanding) more probable.\n\n\nInterpreting predicted probabilities\nTo understand what the model estimates mean in practical terms, let’s examine the predicted probabilities:\n\n\nCode\nce &lt;- conditional_effects(fit_full, effects = \"read\", categorical = TRUE)\n\nplot(ce, plot = FALSE)[[1]] +\n  scale_fill_brewer(palette = \"RdYlGn\", direction = 1) +\n  labs(title = \"Predicted Response Probabilities by Reading Status\",\n       subtitle = \"Model predictions with 95% credible intervals\",\n       x = \"Read Book\",\n       y = \"Predicted Probability\",\n       fill = \"response\") +\n  theme_minimal(base_size = 12) +\n  theme(legend.position = \"right\")\n\n\n\n\n\n\n\n\n\nThe conditional effects plot shows how reading the book shifts the entire distribution toward higher understanding categories. Before reading (read = 0), lower categories have higher probabilities; after reading (read = 1), the distribution shifts substantially toward “something” and “everything.”\nWe can also examine specific fitted values:\n\n\nCode\nnew_data &lt;- data.frame(read = c(0, 1))\nfitted_probs &lt;- fitted(fit_full, newdata = new_data)\n\nfitted_df &lt;- data.frame(\n  read = rep(c(\"Before\", \"After\"), each = 5),\n  category = rep(1:5, times = 2),\n  probability = c(fitted_probs[1, \"Estimate\", ], fitted_probs[2, \"Estimate\",]),\n  lower = c(fitted_probs[1, \"Q2.5\",], fitted_probs[2 , \"Q2.5\",]),\n  upper = c(fitted_probs[1, \"Q97.5\",], fitted_probs[2 , \"Q97.5\",])\n)\n\nggplot(fitted_df, aes(x = factor(category), y = probability, fill = read)) +\n  geom_col(position = \"dodge\", alpha = 0.7, color = \"black\") +\n  geom_errorbar(aes(ymin = lower, ymax = upper), \n                position = position_dodge(0.9), width = 0.2) +\n  scale_fill_manual(values = c(\"Before\" = \"coral\", \"After\" = \"forestgreen\")) +\n  labs(title = \"Model-Predicted Probabilities with 95% Credible Intervals\",\n       x = \"Understanding Category\",\n       y = \"Predicted Probability\",\n       fill = \"Reading Status\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n\nThe fitted probabilities show concrete estimates: for instance, before reading, the probability of responding “nothing” is about 0.38, whereas after reading it drops to about 0.12. Conversely, the probability of responding “everything” increases from about 0.01 to 0.05.\n\n\nPosterior predictive check\nFinally, let’s verify that the model fits the observed data well:\n\npp_check(fit_full, type = \"bars\", ndraws = 100) +\n  labs(title = \"Posterior Predictive Check: Full Model\",\n       subtitle = \"Model predictions compared to observed data\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\nThe posterior predictive distribution closely matches the observed data patterns, indicating good model fit."
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html#recovery-of-the-parameters",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html#recovery-of-the-parameters",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Recovery of the parameters",
    "text": "Recovery of the parameters\nLet’s examine whether the model successfully recovered the true parameters we used to generate the data. We simulated with thresholds \\(\\tau = [-0.5, 0.5, 3, 4.5]\\) and a treatment effect of \\(\\beta = 1.5\\).\n\ntrue_params &lt;- c(thres, beta)\nnames(true_params) &lt;- c(paste0(\"b_Intercept[\", 1:4, \"]\"), \"b_read\")\n\nposterior_draws &lt;- as.array(fit_full,\n                            variable = names(true_params))\n\nmcmc_recover_hist(posterior_draws, true = true_params) +\n  labs(title = \"Parameter Recovery\",\n       subtitle = \"Posterior distributions (histograms) vs. true values (vertical lines)\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\nThe histograms show the posterior distributions for each parameter, with vertical lines indicating the true values used in simulation. We can see that:\n\nThresholds: All four threshold parameters are well-recovered, with posterior distributions centered near the true values\nTreatment effect: The read coefficient is also well-recovered, with the posterior centered around 1.5"
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html#conclusion",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html#conclusion",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Conclusion",
    "text": "Conclusion\nThis short tutorial has demonstrated how cumulative link models provide a principled framework for ordinal regression.\nBy respecting the ordinal nature of the data, rather than treating categories as metric, cumulative link models yield more appropriate inferences for ordered categorical outcomes. The example above is intentionally simple; in cognitive science, data are typically clustered (e.g., by participants or items), which naturally calls for hierarchical models. For an application to ordinal ratings in this setting, see Taylor et al. (2022). For a more general introduction to hierarchical modeling with brms, see chapter 5 of Nicenboim, Schad, and Vasishth (2025)."
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html#how-to-cite-this-post",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html#how-to-cite-this-post",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "How to cite this post",
    "text": "How to cite this post\n\n\n\n\n\n\nTipCitation\n\n\n\n\n\nBibTeX:\n@misc{nicenboim2026bayesianordinalmodelsaveryshortpracticalguide,\n  author = {Nicenboim, Bruno},\n  title = {Bayesian ordinal models: A very short practical guide},\n  year = {2026},\n  month = {January},\n  url = {https://bruno.nicenboim.me/posts/posts/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/}\n}\nAPA:\nNicenboim, B. (2026, January 09). Bayesian ordinal models: A very short practical guide. https://bruno.nicenboim.me/posts/posts/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/"
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html#session-info",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html#session-info",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Session info",
    "text": "Session info\n\n\nR version 4.5.2 (2025-10-31)\nPlatform: x86_64-pc-linux-gnu\nRunning under: Ubuntu 24.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.12.0 \nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.12.0  LAPACK version 3.12.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Europe/Amsterdam\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ggridges_0.5.7      patchwork_1.3.2     bayesplot_1.15.0   \n[4] brms_2.23.0         Rcpp_1.1.1          ggplot2_4.0.1      \n[7] tidytable_0.11.2    extraDistr_1.10.0.1\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6            tensorA_0.36.2.1        xfun_0.55              \n [4] QuickJSR_1.8.1          htmlwidgets_1.6.4       processx_3.8.6         \n [7] inline_0.3.21           lattice_0.22-7          callr_3.7.6            \n[10] vctrs_0.6.5             tools_4.5.2             ps_1.9.1               \n[13] generics_0.1.4          stats4_4.5.2            parallel_4.5.2         \n[16] tibble_3.3.1            pkgconfig_2.0.3         Matrix_1.7-4           \n[19] data.table_1.18.0       checkmate_2.3.3         RColorBrewer_1.1-3     \n[22] S7_0.2.1                distributional_0.6.0    RcppParallel_5.1.11-1  \n[25] lifecycle_1.0.5         compiler_4.5.2          farver_2.1.2           \n[28] stringr_1.6.0           Brobdingnag_1.2-9       codetools_0.2-20       \n[31] htmltools_0.5.9         yaml_2.3.12             tidyr_1.3.2            \n[34] pillar_1.11.1           StanHeaders_2.36.0.9000 bridgesampling_1.2-1   \n[37] abind_1.4-8             nlme_3.1-168            posterior_1.6.1.9000   \n[40] rstan_2.36.0.9000       tidyselect_1.2.1        digest_0.6.39          \n[43] mvtnorm_1.3-3           stringi_1.8.7           purrr_1.2.1            \n[46] dplyr_1.1.4             reshape2_1.4.5          labeling_0.4.3         \n[49] fastmap_1.2.0           grid_4.5.2              cli_3.6.5              \n[52] magrittr_2.0.4          loo_2.9.0.9000          pkgbuild_1.4.8         \n[55] withr_3.0.2             scales_1.4.0            backports_1.5.0        \n[58] rmarkdown_2.30          matrixStats_1.5.0       otel_0.2.0             \n[61] gridExtra_2.3           coda_0.19-4.1           evaluate_1.0.5         \n[64] knitr_1.51              rstantools_2.6.0        rlang_1.1.7            \n[67] glue_1.8.0              jsonlite_2.0.0          R6_2.6.1               \n[70] plyr_1.8.9"
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html#references",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html#references",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "References",
    "text": "References\n\n\nBürkner, Paul-Christian, and Matti Vuorre. 2019. “Ordinal Regression Models in Psychology: A Tutorial.” Advances in Methods and Practices in Psychological Science 2 (1): 77–101. https://doi.org/10.1177/2515245918823199.\n\n\nNicenboim, Bruno, Daniel J. Schad, and Shravan Vasishth. 2025. Introduction to Bayesian Data Analysis for Cognitive Science. 1st ed. Chapman; Hall/CRC. https://doi.org/10.1201/9780429342646.\n\n\nTaylor, Jack E., Guillaume A. Rousselet, Christoph Scheepers, and Sara C. Sereno. 2022. “Rating Norms Should Be Calculated from Cumulative Link Mixed Effects Models.” Behavior Research Methods 55 (5): 2175–96. https://doi.org/10.3758/s13428-022-01814-7."
  },
  {
    "objectID": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html#footnotes",
    "href": "posts/posts/2026-01-09-ordinal-models/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide-archive/2026-01-09-bayesian-ordinal-models-a-very-short-practical-guide/index.html#footnotes",
    "title": "Bayesian ordinal models: A very short practical guide",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe logistic distribution is not that different from the normal distribution: it is a symmetrical bell-shaped distribution. The reason for using this distribution rather than the normal distribution is that the modeling will need to rely on the cumulative density function (CDF), and the logistic tends to be more numerically stable↩︎\nShameless self-promotion of Nicenboim, Schad, and Vasishth (2025).↩︎"
  }
]